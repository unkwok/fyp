{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0c507a",
   "metadata": {},
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad005eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from stockstats import StockDataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03bed7",
   "metadata": {},
   "source": [
    "### Set the data source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2436b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data source path\n",
    "interval = \"daily\"\n",
    "region = \"us\"\n",
    "ex_product = \"nasdaq stocks\"\n",
    "section = \"1\"\n",
    "stock = \"aapl\"\n",
    "data_path = \"test_data/\"+interval+\"/\"+region+\"/\"+ex_product+\"/\"+section+\"/\"+stock+\".\"+region+\".txt\"\n",
    "\n",
    "# Use Apple .Inc stock for training\n",
    "\n",
    "# Extract only the OLHC\n",
    "column_to_use = [\"OPEN\",\"LOW\",\"HIGH\",\"CLOSE\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f91fe",
   "metadata": {},
   "source": [
    "### Load the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92c24ac-3419-4a42-973b-e21ae036c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ori_data = pd.read_csv(data_path, sep=\",\")\n",
    "\n",
    "# Rename the column names\n",
    "ori_data.columns = [colname[1:-1] for colname in ori_data.columns]\n",
    "\n",
    "# Drop the unnecessary\n",
    "ori_data.index = ori_data[\"DATE\"]\n",
    "ori_data = ori_data.drop(columns=['DATE','PER','TIME', 'TICKER', 'OPENINT'])\n",
    "ori_data.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be882ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19840907</th>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.10274</td>\n",
       "      <td>0.10028</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>96970899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840910</th>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.09905</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>75265237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840911</th>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.10456</td>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.10274</td>\n",
       "      <td>177479896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840912</th>\n",
       "      <td>0.10274</td>\n",
       "      <td>0.10334</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>155043826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840913</th>\n",
       "      <td>0.10518</td>\n",
       "      <td>0.10548</td>\n",
       "      <td>0.10518</td>\n",
       "      <td>0.10518</td>\n",
       "      <td>241475025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211021</th>\n",
       "      <td>148.81000</td>\n",
       "      <td>149.64000</td>\n",
       "      <td>147.87000</td>\n",
       "      <td>149.48000</td>\n",
       "      <td>61420990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211022</th>\n",
       "      <td>149.69000</td>\n",
       "      <td>150.18000</td>\n",
       "      <td>148.64000</td>\n",
       "      <td>148.69000</td>\n",
       "      <td>58883443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211025</th>\n",
       "      <td>148.68000</td>\n",
       "      <td>149.37000</td>\n",
       "      <td>147.62110</td>\n",
       "      <td>148.64000</td>\n",
       "      <td>50720556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211026</th>\n",
       "      <td>149.33000</td>\n",
       "      <td>150.84000</td>\n",
       "      <td>149.01010</td>\n",
       "      <td>149.32000</td>\n",
       "      <td>60893395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211027</th>\n",
       "      <td>149.36000</td>\n",
       "      <td>149.73000</td>\n",
       "      <td>148.49000</td>\n",
       "      <td>148.85000</td>\n",
       "      <td>55925403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9362 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open       high        low      close     volume\n",
       "DATE                                                           \n",
       "19840907    0.10150    0.10274    0.10028    0.10150   96970899\n",
       "19840910    0.10150    0.10181    0.09905    0.10090   75265237\n",
       "19840911    0.10181    0.10456    0.10181    0.10274  177479896\n",
       "19840912    0.10274    0.10334    0.09966    0.09966  155043826\n",
       "19840913    0.10518    0.10548    0.10518    0.10518  241475025\n",
       "...             ...        ...        ...        ...        ...\n",
       "20211021  148.81000  149.64000  147.87000  149.48000   61420990\n",
       "20211022  149.69000  150.18000  148.64000  148.69000   58883443\n",
       "20211025  148.68000  149.37000  147.62110  148.64000   50720556\n",
       "20211026  149.33000  150.84000  149.01010  149.32000   60893395\n",
       "20211027  149.36000  149.73000  148.49000  148.85000   55925403\n",
       "\n",
       "[9362 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966120a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use online package to generate additional features\n",
    "x = StockDataFrame(ori_data)\n",
    "data = x[['open','high','low','close','volume',\n",
    "          'boll', 'boll_ub', 'boll_lb',\n",
    "          'macd', 'macdh', 'macds',\n",
    "          'rsi_11', 'rsi_14', 'rsi_21']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1f7671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>boll</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdh</th>\n",
       "      <th>macds</th>\n",
       "      <th>rsi_11</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>rsi_21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19840907</th>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.10274</td>\n",
       "      <td>0.10028</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>96970899</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840910</th>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.09905</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>75265237</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.102049</td>\n",
       "      <td>0.100351</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840911</th>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.10456</td>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.10274</td>\n",
       "      <td>177479896</td>\n",
       "      <td>0.101713</td>\n",
       "      <td>0.103590</td>\n",
       "      <td>0.099837</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>77.134146</td>\n",
       "      <td>76.758045</td>\n",
       "      <td>76.303318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840912</th>\n",
       "      <td>0.10274</td>\n",
       "      <td>0.10334</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>155043826</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>0.098638</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>31.870001</td>\n",
       "      <td>32.201239</td>\n",
       "      <td>32.592743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840913</th>\n",
       "      <td>0.10518</td>\n",
       "      <td>0.10548</td>\n",
       "      <td>0.10518</td>\n",
       "      <td>0.10518</td>\n",
       "      <td>241475025</td>\n",
       "      <td>0.101996</td>\n",
       "      <td>0.106191</td>\n",
       "      <td>0.097801</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>68.412723</td>\n",
       "      <td>68.025100</td>\n",
       "      <td>67.561551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211021</th>\n",
       "      <td>148.81000</td>\n",
       "      <td>149.64000</td>\n",
       "      <td>147.87000</td>\n",
       "      <td>149.48000</td>\n",
       "      <td>61420990</td>\n",
       "      <td>143.875000</td>\n",
       "      <td>149.793245</td>\n",
       "      <td>137.956755</td>\n",
       "      <td>0.375617</td>\n",
       "      <td>1.069014</td>\n",
       "      <td>-0.693396</td>\n",
       "      <td>65.673205</td>\n",
       "      <td>61.532287</td>\n",
       "      <td>57.199864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211022</th>\n",
       "      <td>149.69000</td>\n",
       "      <td>150.18000</td>\n",
       "      <td>148.64000</td>\n",
       "      <td>148.69000</td>\n",
       "      <td>58883443</td>\n",
       "      <td>143.963500</td>\n",
       "      <td>150.121546</td>\n",
       "      <td>137.805454</td>\n",
       "      <td>0.577001</td>\n",
       "      <td>1.016318</td>\n",
       "      <td>-0.439317</td>\n",
       "      <td>61.924694</td>\n",
       "      <td>58.867114</td>\n",
       "      <td>55.611436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211025</th>\n",
       "      <td>148.68000</td>\n",
       "      <td>149.37000</td>\n",
       "      <td>147.62110</td>\n",
       "      <td>148.64000</td>\n",
       "      <td>50720556</td>\n",
       "      <td>144.127000</td>\n",
       "      <td>150.607481</td>\n",
       "      <td>137.646519</td>\n",
       "      <td>0.724216</td>\n",
       "      <td>0.930826</td>\n",
       "      <td>-0.206610</td>\n",
       "      <td>61.679591</td>\n",
       "      <td>58.693837</td>\n",
       "      <td>55.508996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211026</th>\n",
       "      <td>149.33000</td>\n",
       "      <td>150.84000</td>\n",
       "      <td>149.01010</td>\n",
       "      <td>149.32000</td>\n",
       "      <td>60893395</td>\n",
       "      <td>144.497500</td>\n",
       "      <td>151.284341</td>\n",
       "      <td>137.710659</td>\n",
       "      <td>0.885547</td>\n",
       "      <td>0.873726</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>63.821803</td>\n",
       "      <td>60.401009</td>\n",
       "      <td>56.649320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211027</th>\n",
       "      <td>149.36000</td>\n",
       "      <td>149.73000</td>\n",
       "      <td>148.49000</td>\n",
       "      <td>148.85000</td>\n",
       "      <td>55925403</td>\n",
       "      <td>144.798500</td>\n",
       "      <td>151.804399</td>\n",
       "      <td>137.792601</td>\n",
       "      <td>0.964362</td>\n",
       "      <td>0.762033</td>\n",
       "      <td>0.202329</td>\n",
       "      <td>61.219811</td>\n",
       "      <td>58.598318</td>\n",
       "      <td>55.614834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9362 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open       high        low      close     volume        boll  \\\n",
       "DATE                                                                          \n",
       "19840907    0.10150    0.10274    0.10028    0.10150   96970899    0.101500   \n",
       "19840910    0.10150    0.10181    0.09905    0.10090   75265237    0.101200   \n",
       "19840911    0.10181    0.10456    0.10181    0.10274  177479896    0.101713   \n",
       "19840912    0.10274    0.10334    0.09966    0.09966  155043826    0.101200   \n",
       "19840913    0.10518    0.10548    0.10518    0.10518  241475025    0.101996   \n",
       "...             ...        ...        ...        ...        ...         ...   \n",
       "20211021  148.81000  149.64000  147.87000  149.48000   61420990  143.875000   \n",
       "20211022  149.69000  150.18000  148.64000  148.69000   58883443  143.963500   \n",
       "20211025  148.68000  149.37000  147.62110  148.64000   50720556  144.127000   \n",
       "20211026  149.33000  150.84000  149.01010  149.32000   60893395  144.497500   \n",
       "20211027  149.36000  149.73000  148.49000  148.85000   55925403  144.798500   \n",
       "\n",
       "             boll_ub     boll_lb      macd     macdh     macds     rsi_11  \\\n",
       "DATE                                                                        \n",
       "19840907         NaN         NaN  0.000000  0.000000  0.000000        NaN   \n",
       "19840910    0.102049    0.100351 -0.000013 -0.000006 -0.000007   0.000000   \n",
       "19840911    0.103590    0.099837  0.000040  0.000028  0.000012  77.134146   \n",
       "19840912    0.103762    0.098638 -0.000048 -0.000040 -0.000008  31.870001   \n",
       "19840913    0.106191    0.097801  0.000125  0.000094  0.000031  68.412723   \n",
       "...              ...         ...       ...       ...       ...        ...   \n",
       "20211021  149.793245  137.956755  0.375617  1.069014 -0.693396  65.673205   \n",
       "20211022  150.121546  137.805454  0.577001  1.016318 -0.439317  61.924694   \n",
       "20211025  150.607481  137.646519  0.724216  0.930826 -0.206610  61.679591   \n",
       "20211026  151.284341  137.710659  0.885547  0.873726  0.011821  63.821803   \n",
       "20211027  151.804399  137.792601  0.964362  0.762033  0.202329  61.219811   \n",
       "\n",
       "             rsi_14     rsi_21  \n",
       "DATE                            \n",
       "19840907        NaN        NaN  \n",
       "19840910   0.000000   0.000000  \n",
       "19840911  76.758045  76.303318  \n",
       "19840912  32.201239  32.592743  \n",
       "19840913  68.025100  67.561551  \n",
       "...             ...        ...  \n",
       "20211021  61.532287  57.199864  \n",
       "20211022  58.867114  55.611436  \n",
       "20211025  58.693837  55.508996  \n",
       "20211026  60.401009  56.649320  \n",
       "20211027  58.598318  55.614834  \n",
       "\n",
       "[9362 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28b28b",
   "metadata": {},
   "source": [
    "# CNN_LSTM (Direction Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36c4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test data\n",
    "def custom_split(data,start,end):\n",
    "    train = (data.index >= start) & (data.index <= end)\n",
    "    train_X = data[train]\n",
    "    \n",
    "    return train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6cd6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = custom_split(data,start = 20130101,end = 20171031)\n",
    "valid_X = custom_split(data,start = 20171101,end = 20181231)\n",
    "test_X = custom_split(data,start = 20190101,end = 20201231)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce609a",
   "metadata": {},
   "source": [
    "### Label the target result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e4e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we use 10 days price data to predict opening price of the 11th day\n",
    "num_day_to_predict = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7f127afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_result_target_price(X,num_day,result_col_name = \"Action\"):\n",
    "    y = pd.DataFrame(np.nan, index=X.index, columns=[result_col_name])\n",
    "    status = \"Hold\"\n",
    "    for i in range(len(X)-num_day):\n",
    "        last_10_day_mean = np.mean(X.iloc[i:i+num_day,0])\n",
    "        if X.iloc[i+num_day,0]>last_10_day_mean*1.01:\n",
    "            y.iloc[i+num_day_to_predict,0] = 1\n",
    "            status = \"Buy\"\n",
    "            if i <= 10:\n",
    "                print(status)\n",
    "        elif X.iloc[i+num_day,0]<last_10_day_mean/1.01:\n",
    "            y.iloc[i+num_day_to_predict,0] = 0\n",
    "            status = \"Sell\"\n",
    "            if i <= 10:\n",
    "                print(status)\n",
    "        else:\n",
    "            if status == \"Hold\" or status == \"Sell\":\n",
    "                y.iloc[i+num_day_to_predict,0] = 0\n",
    "            elif status == \"Buy\":\n",
    "                y.iloc[i+num_day_to_predict,0] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b7fcaaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Sell\n",
      "Buy\n",
      "Buy\n",
      "Buy\n",
      "Sell\n",
      "Buy\n",
      "Buy\n",
      "Buy\n",
      "Buy\n",
      "Buy\n",
      "Buy\n",
      "Buy\n",
      "Buy\n",
      "Buy\n"
     ]
    }
   ],
   "source": [
    "# y value meaning {1: Buy, 0: Sell}\n",
    "train_y = produce_result_target_price(train_X,num_day_to_predict)\n",
    "valid_y = produce_result_target_price(valid_X,num_day_to_predict)\n",
    "test_y = produce_result_target_price(test_X,num_day_to_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "db1064e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20190102</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190103</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190104</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190107</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190108</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190109</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190110</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190111</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190114</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190115</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190116</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190117</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190118</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190122</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190123</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190124</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190125</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190128</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190129</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190130</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190131</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190201</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190204</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190205</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190206</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190207</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190208</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190211</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190212</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190213</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Action\n",
       "DATE            \n",
       "20190102     NaN\n",
       "20190103     NaN\n",
       "20190104     NaN\n",
       "20190107     NaN\n",
       "20190108     NaN\n",
       "20190109     NaN\n",
       "20190110     NaN\n",
       "20190111     NaN\n",
       "20190114     NaN\n",
       "20190115     NaN\n",
       "20190116     1.0\n",
       "20190117     1.0\n",
       "20190118     1.0\n",
       "20190122     1.0\n",
       "20190123     1.0\n",
       "20190124     1.0\n",
       "20190125     1.0\n",
       "20190128     1.0\n",
       "20190129     1.0\n",
       "20190130     1.0\n",
       "20190131     1.0\n",
       "20190201     1.0\n",
       "20190204     1.0\n",
       "20190205     1.0\n",
       "20190206     1.0\n",
       "20190207     1.0\n",
       "20190208     1.0\n",
       "20190211     1.0\n",
       "20190212     1.0\n",
       "20190213     1.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a8ca1",
   "metadata": {},
   "source": [
    "### Transform the X, y data into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c8b8773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_to_tensor(X,y,num_day):\n",
    "    # Initiate tensor for X\n",
    "    x_first = X.iloc[0:num_day,:]\n",
    "    x_mean = x_first.mean(axis=0) # Get the mean of the 10-day frame\n",
    "    x_std = x_first.std(axis=0) # Get the std of the 10-day frame\n",
    "    x_first = x_first.sub(x_mean, axis=1).div(x_std, axis=1) # Normalize the 10-day frame here\n",
    "    x_tf_data = [tf.convert_to_tensor(np.array(x_first),dtype = tf.float32)]\n",
    "    \n",
    "    for i in range(1,len(X)-num_day):   \n",
    "        x_window = X.iloc[i:i+num_day,:] # Set the window as a 10-day frame \n",
    "        x_mean = x_window.mean(axis=0) # Get the mean of the 10-day frame\n",
    "        x_std = x_window.std(axis=0) # Get the std of the 10-day frame\n",
    "        x_window = x_window.sub(x_mean, axis=1).div(x_std, axis=1) # Normalize the 10-day frame here\n",
    "        \n",
    "        x_next_tf = tf.convert_to_tensor(np.array(x_window),dtype = tf.float32)\n",
    "        x_tf_data = tf.concat([x_tf_data, [x_next_tf]], 0)\n",
    "        \n",
    "    temp_y = y.dropna()\n",
    "    y_tf_data = []\n",
    "    for ind in temp_y.index:\n",
    "        if temp_y.loc[ind,\"Action\"] == 1:\n",
    "            y_tf_data.append([1,0])\n",
    "        elif temp_y.loc[ind,\"Action\"] == 0:\n",
    "            y_tf_data.append([0,1])\n",
    "    y_tf_data = tf.convert_to_tensor(y_tf_data)\n",
    "        \n",
    "    return (tf.reshape(x_tf_data,(-1,10,14,1)),y_tf_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "87da2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_X,tf_train_y = transform_data_to_tensor(train_X,train_y,num_day_to_predict)\n",
    "tf_valid_X,tf_valid_y = transform_data_to_tensor(valid_X,valid_y,num_day_to_predict)\n",
    "tf_test_X,tf_test_y = transform_data_to_tensor(test_X,test_y,num_day_to_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "57f49a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1208, 10, 14, 1)\n",
      "(1208, 2)\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'int32'>\n",
      "(282, 10, 14, 1)\n",
      "(282, 2)\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'int32'>\n",
      "(495, 10, 14, 1)\n",
      "(495, 2)\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(tf_train_X.shape)\n",
    "print(tf_train_y.shape)\n",
    "print(tf_train_X.dtype)\n",
    "print(tf_train_y.dtype)\n",
    "\n",
    "print(tf_valid_X.shape)\n",
    "print(tf_valid_y.shape)\n",
    "print(tf_valid_X.dtype)\n",
    "print(tf_valid_y.dtype)\n",
    "\n",
    "print(tf_test_X.shape)\n",
    "print(tf_test_y.shape)\n",
    "print(tf_test_X.dtype)\n",
    "print(tf_test_y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e64c36",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "359468c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def myModel(input_shape,\n",
    "            encoder_unit = 100,\n",
    "            repeat_vector_n = 10):\n",
    "    \n",
    "    inputs = layers.Input(input_shape)\n",
    "    \n",
    "    print(\"Input: \",inputs.shape)\n",
    "    \n",
    "    # First Convolution + MaxPooling + Dropout\n",
    "    x = layers.Conv2D(filters = 64,kernel_size=(3,3), strides = (1,1), activation='relu', padding='valid')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2),strides=(2,1), padding='valid')(x)\n",
    "    x = layers.Dropout(rate = 0.01)(x)\n",
    "    print(\"1 Cov: \",x.shape)\n",
    "    \n",
    "    # Second Convolution + MaxPooling + Dropout\n",
    "    x = layers.Conv2D(filters = 16,kernel_size=(3,3), strides = (1,1), activation='relu', padding='valid')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2),strides=(2,1), padding='valid')(x)\n",
    "    x = layers.Dropout(rate = 0.01)(x)\n",
    "    print(\"2 Cov: \",x.shape)\n",
    "    \n",
    "    # Flatten Layer\n",
    "    x = layers.Flatten()(x)\n",
    "    print(\"Flatten: \",x.shape)\n",
    "    \n",
    "    # Repeat Vector Layer\n",
    "    x = layers.RepeatVector(n = repeat_vector_n)(x)\n",
    "    print(\"RepeatVector: \",x.shape)\n",
    "    \n",
    "    # Connect to LSTM\n",
    "    x = layers.LSTM(units = encoder_unit, input_shape=(5,1))(x)\n",
    "    print(\"LSTM: \",x.shape)\n",
    "    \n",
    "    # Second Flatten Layer\n",
    "    x = layers.Flatten()(x)\n",
    "    print(\"Flatten: \",x.shape)\n",
    "    \n",
    "    # Add the Dense Layer with relu activation\n",
    "    x = layers.Dense(units = 50,activation = \"relu\")(x)\n",
    "    print(\"1 Dense: \",x.shape)\n",
    "    \n",
    "    # Add the last Dense Layer with sigmoid activation\n",
    "    outputs = layers.Dense(units = 2,activation = \"softmax\")(x)\n",
    "    print(\"Output: \",outputs.shape)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fc4f2",
   "metadata": {},
   "source": [
    "### Model Training and Fitting and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "72215124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  (None, 10, 14, 1)\n",
      "1 Cov:  (None, 4, 11, 64)\n",
      "2 Cov:  (None, 1, 8, 16)\n",
      "Flatten:  (None, 128)\n",
      "RepeatVector:  (None, 100, 128)\n",
      "LSTM:  (None, 50)\n",
      "Flatten:  (None, 50)\n",
      "1 Dense:  (None, 50)\n",
      "Output:  (None, 2)\n",
      "Train on 1208 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 16:55:20.854651: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_185556_186041' and '__inference___backward_standard_lstm_185556_186041_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_186214' both implement 'lstm_a1c4cdea-afcf-4fee-b75d-264f2e534e9e' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233/1208 [==============================] - 29s 24ms/sample - loss: 0.1308 - root_mean_squared_error: 0.3623\n",
      "Epoch 2/30\n",
      "1233/1208 [==============================] - 18s 15ms/sample - loss: 0.1071 - root_mean_squared_error: 0.3250\n",
      "Epoch 3/30\n",
      "1233/1208 [==============================] - 18s 14ms/sample - loss: 0.0823 - root_mean_squared_error: 0.2868\n",
      "Epoch 4/30\n",
      "1233/1208 [==============================] - 18s 14ms/sample - loss: 0.0688 - root_mean_squared_error: 0.2625\n",
      "Epoch 5/30\n",
      "1233/1208 [==============================] - 18s 15ms/sample - loss: 0.0788 - root_mean_squared_error: 0.2807\n",
      "Epoch 6/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0615 - root_mean_squared_error: 0.2512\n",
      "Epoch 7/30\n",
      "1233/1208 [==============================] - 14s 12ms/sample - loss: 0.0599 - root_mean_squared_error: 0.2426\n",
      "Epoch 8/30\n",
      "1233/1208 [==============================] - 14s 12ms/sample - loss: 0.0473 - root_mean_squared_error: 0.2201\n",
      "Epoch 9/30\n",
      "1233/1208 [==============================] - 18s 15ms/sample - loss: 0.0510 - root_mean_squared_error: 0.2271\n",
      "Epoch 10/30\n",
      "1233/1208 [==============================] - 19s 15ms/sample - loss: 0.0474 - root_mean_squared_error: 0.2176\n",
      "Epoch 11/30\n",
      "1233/1208 [==============================] - 18s 14ms/sample - loss: 0.0595 - root_mean_squared_error: 0.2435\n",
      "Epoch 12/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0475 - root_mean_squared_error: 0.2197\n",
      "Epoch 13/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0352 - root_mean_squared_error: 0.1835\n",
      "Epoch 14/30\n",
      "1233/1208 [==============================] - 18s 15ms/sample - loss: 0.0496 - root_mean_squared_error: 0.2233\n",
      "Epoch 15/30\n",
      "1233/1208 [==============================] - 18s 15ms/sample - loss: 0.0341 - root_mean_squared_error: 0.1846\n",
      "Epoch 16/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0332 - root_mean_squared_error: 0.1818\n",
      "Epoch 17/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0247 - root_mean_squared_error: 0.1579\n",
      "Epoch 18/30\n",
      "1233/1208 [==============================] - 19s 15ms/sample - loss: 0.0334 - root_mean_squared_error: 0.1799\n",
      "Epoch 19/30\n",
      "1233/1208 [==============================] - 18s 15ms/sample - loss: 0.0349 - root_mean_squared_error: 0.1876\n",
      "Epoch 20/30\n",
      "1233/1208 [==============================] - 16s 13ms/sample - loss: 0.0214 - root_mean_squared_error: 0.1487\n",
      "Epoch 21/30\n",
      "1233/1208 [==============================] - 16s 13ms/sample - loss: 0.0319 - root_mean_squared_error: 0.1783\n",
      "Epoch 22/30\n",
      "1233/1208 [==============================] - 17s 13ms/sample - loss: 0.0277 - root_mean_squared_error: 0.1644\n",
      "Epoch 23/30\n",
      "1233/1208 [==============================] - 18s 14ms/sample - loss: 0.0276 - root_mean_squared_error: 0.1710\n",
      "Epoch 24/30\n",
      "1233/1208 [==============================] - 20s 16ms/sample - loss: 0.0267 - root_mean_squared_error: 0.1643\n",
      "Epoch 25/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0232 - root_mean_squared_error: 0.1564\n",
      "Epoch 26/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0210 - root_mean_squared_error: 0.1452\n",
      "Epoch 27/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0229 - root_mean_squared_error: 0.1512\n",
      "Epoch 28/30\n",
      "1233/1208 [==============================] - 17s 14ms/sample - loss: 0.0163 - root_mean_squared_error: 0.1279\n",
      "Epoch 29/30\n",
      "1233/1208 [==============================] - 18s 14ms/sample - loss: 0.0234 - root_mean_squared_error: 0.1523\n",
      "Epoch 30/30\n",
      "1233/1208 [==============================] - 18s 15ms/sample - loss: 0.0224 - root_mean_squared_error: 0.1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 17:04:09.133982: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_191041_specialized_for_model_12_lstm_12_StatefulPartitionedCall_at___inference_distributed_function_191394' and '__inference_standard_lstm_191041' both implement 'lstm_780799df-4f34-4515-bd1e-4f8e596a76ef' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "282/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2s 8ms/sample - loss: 0.0727 - root_mean_squared_error: 0.2444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05973848860367393, 0.24441457]\n",
      "===== Summary =====\n",
      "Epoch:  30\n",
      "Batch Size:  50\n",
      "Optimizer:  Adam\n",
      "Learning Rate:  0.005\n",
      "Encoder Units:  50\n",
      "Loss Function:  Categorical CrossEntropy\n",
      "Metrics:  [<tensorflow.python.keras.metrics.RootMeanSquaredError object at 0x7fd43b8989d0>]\n",
      "Validation:  [0.05973848860367393, 0.24441457]\n",
      "INFO:tensorflow:Assets written to: model/cnn_lstm_classify_best/assets\n"
     ]
    }
   ],
   "source": [
    "optimizer_list = [\"Adam\"]\n",
    "epoch_list = [30]\n",
    "batch_list = [50]\n",
    "encoder_list = [50]\n",
    "lr_list = [0.005]\n",
    "train_df = pd.DataFrame(columns = [\"Epoch\",\"Batch\",\"Optimizer\",\"LR\",\"Encoder Unit\",\"Loss\",\"Metrics\",\"Validation\"])\n",
    "best_model = \"\"\n",
    "best_valid = 99999\n",
    "metrics = [keras.metrics.RootMeanSquaredError()]\n",
    "\n",
    "\n",
    "for opti in optimizer_list:\n",
    "    for epochs in epoch_list:\n",
    "        for batchs in batch_list:\n",
    "            for lr in lr_list:\n",
    "                for encoder_u in encoder_list:\n",
    "\n",
    "                    model = myModel(input_shape=(num_day_to_predict,train_X.shape[1],1),\n",
    "                                    encoder_unit = encoder_u,\n",
    "                                    repeat_vector_n = 100\n",
    "                                   )\n",
    "\n",
    "                    if opti == \"Adam\":\n",
    "                        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "\n",
    "                    model.compile(\n",
    "                        optimizer=optimizer,\n",
    "                        loss=keras.losses.MeanSquaredError(),\n",
    "                        metrics=metrics,\n",
    "                    )\n",
    "\n",
    "                    history = model.fit(\n",
    "                            tf_train_X,\n",
    "                            tf_train_y,\n",
    "                            epochs = epochs,\n",
    "                            steps_per_epoch = batchs,\n",
    "                        )\n",
    "\n",
    "                    results = model.evaluate(tf_valid_X, tf_valid_y, batch_size=batchs)\n",
    "                    print(results)\n",
    "                    print(\"===== Summary =====\")\n",
    "                    print(\"Epoch: \",epochs)\n",
    "                    print(\"Batch Size: \",batchs)\n",
    "                    print(\"Optimizer: \",opti)\n",
    "                    print(\"Learning Rate: \",lr)\n",
    "                    print(\"Encoder Units: \",encoder_u)\n",
    "                    print(\"Loss Function: \", \"Categorical CrossEntropy\")\n",
    "                    print(\"Metrics: \", metrics)\n",
    "                    print(\"Validation: \",results)\n",
    "                    if results[0] < best_valid:\n",
    "                        best_valid = results[0]\n",
    "                        best_model = model\n",
    "                    train_df = train_df.append({\"Epoch\": epochs,\n",
    "                                                \"Batch\": batchs,\n",
    "                                                \"Optimizer\": opti,\n",
    "                                                \"LR\": lr,\n",
    "                                                \"Encoder Unit\": encoder_u,\n",
    "                                                \"Loss\": \"Categorical CrossEntropy\",\n",
    "                                                \"Metrics\": metrics,\n",
    "                                                \"Validation\":results}, ignore_index=True)\n",
    "best_model.save(\"model/cnn_lstm_classify_best\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1049860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_values(by=[\"Validation\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6201ca",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "06c93eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('model/cnn_lstm_classify_best')\n",
    "\n",
    "predictions = loaded_model.predict(tf_test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "470d3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (495, 2)\n",
      "[[9.34880912e-01 6.51190206e-02]\n",
      " [9.90257740e-01 9.74231213e-03]\n",
      " [9.89017606e-01 1.09823821e-02]\n",
      " [9.88777339e-01 1.12226820e-02]\n",
      " [9.82177496e-01 1.78225078e-02]\n",
      " [9.60869968e-01 3.91300432e-02]\n",
      " [9.47850943e-01 5.21490388e-02]\n",
      " [9.77309287e-01 2.26907376e-02]\n",
      " [9.43906367e-01 5.60936555e-02]\n",
      " [9.83014464e-01 1.69855319e-02]\n",
      " [9.82295275e-01 1.77047253e-02]\n",
      " [9.86169338e-01 1.38306404e-02]\n",
      " [9.66689527e-01 3.33104879e-02]\n",
      " [9.56961215e-01 4.30387408e-02]\n",
      " [9.96375740e-01 3.62426043e-03]\n",
      " [9.96503472e-01 3.49657144e-03]\n",
      " [9.96398211e-01 3.60177993e-03]\n",
      " [9.91234004e-01 8.76602251e-03]\n",
      " [9.96225715e-01 3.77426762e-03]\n",
      " [9.94110048e-01 5.88991819e-03]\n",
      " [9.97325063e-01 2.67492351e-03]\n",
      " [9.98383641e-01 1.61640195e-03]\n",
      " [9.65372622e-01 3.46274264e-02]\n",
      " [8.14643443e-01 1.85356542e-01]\n",
      " [9.96572614e-01 3.42737813e-03]\n",
      " [9.96969402e-01 3.03063751e-03]\n",
      " [9.94525790e-01 5.47421491e-03]\n",
      " [9.95435536e-01 4.56448132e-03]\n",
      " [9.86292839e-01 1.37071740e-02]\n",
      " [9.58889425e-01 4.11105528e-02]\n",
      " [9.14200842e-01 8.57992172e-02]\n",
      " [9.39470470e-01 6.05295710e-02]\n",
      " [9.89262402e-01 1.07376231e-02]\n",
      " [9.48170245e-01 5.18297590e-02]\n",
      " [9.57731903e-01 4.22680862e-02]\n",
      " [9.21979666e-01 7.80203268e-02]\n",
      " [7.14906724e-03 9.92850900e-01]\n",
      " [9.52422321e-01 4.75776419e-02]\n",
      " [9.37930286e-01 6.20697141e-02]\n",
      " [9.90381420e-01 9.61861387e-03]\n",
      " [9.57922220e-01 4.20777760e-02]\n",
      " [9.94832754e-01 5.16728498e-03]\n",
      " [9.87748921e-01 1.22510744e-02]\n",
      " [9.92869556e-01 7.13040587e-03]\n",
      " [9.92726922e-01 7.27312686e-03]\n",
      " [9.72222090e-01 2.77779158e-02]\n",
      " [9.83486772e-01 1.65132862e-02]\n",
      " [8.48945379e-01 1.51054606e-01]\n",
      " [8.90618205e-01 1.09381765e-01]\n",
      " [9.96698558e-01 3.30135436e-03]\n",
      " [9.96356905e-01 3.64307268e-03]\n",
      " [9.82027531e-01 1.79724079e-02]\n",
      " [9.95950580e-01 4.04942362e-03]\n",
      " [9.89762008e-01 1.02379955e-02]\n",
      " [9.89211559e-01 1.07883923e-02]\n",
      " [9.90194499e-01 9.80545860e-03]\n",
      " [9.79396701e-01 2.06033159e-02]\n",
      " [9.84993994e-01 1.50059490e-02]\n",
      " [9.94180441e-01 5.81963174e-03]\n",
      " [9.95945752e-01 4.05429769e-03]\n",
      " [9.94698286e-01 5.30172372e-03]\n",
      " [9.90901470e-01 9.09849443e-03]\n",
      " [9.86862898e-01 1.31370537e-02]\n",
      " [9.88907754e-01 1.10921795e-02]\n",
      " [9.78496134e-01 2.15039309e-02]\n",
      " [9.29361582e-01 7.06384480e-02]\n",
      " [5.75536549e-01 4.24463421e-01]\n",
      " [9.83093381e-01 1.69066209e-02]\n",
      " [9.95217443e-01 4.78255609e-03]\n",
      " [9.93953168e-01 6.04679063e-03]\n",
      " [9.72561002e-01 2.74389796e-02]\n",
      " [9.57914352e-01 4.20857258e-02]\n",
      " [8.78217071e-02 9.12178338e-01]\n",
      " [9.57368135e-01 4.26318981e-02]\n",
      " [9.02402520e-01 9.75975096e-02]\n",
      " [9.64072645e-01 3.59273851e-02]\n",
      " [7.65268862e-01 2.34731138e-01]\n",
      " [7.66632557e-01 2.33367428e-01]\n",
      " [8.56640220e-01 1.43359810e-01]\n",
      " [6.06120098e-03 9.93938804e-01]\n",
      " [5.72161376e-03 9.94278312e-01]\n",
      " [6.91395719e-03 9.93086100e-01]\n",
      " [4.35834331e-03 9.95641708e-01]\n",
      " [5.41525288e-03 9.94584739e-01]\n",
      " [3.88766453e-03 9.96112406e-01]\n",
      " [3.34982760e-03 9.96650159e-01]\n",
      " [3.57301719e-03 9.96427000e-01]\n",
      " [3.86751513e-03 9.96132493e-01]\n",
      " [6.14295201e-03 9.93857086e-01]\n",
      " [2.83825421e-03 9.97161746e-01]\n",
      " [3.60446423e-03 9.96395528e-01]\n",
      " [9.39151552e-03 9.90608454e-01]\n",
      " [5.77332079e-03 9.94226694e-01]\n",
      " [6.49944833e-03 9.93500531e-01]\n",
      " [5.29488875e-03 9.94705141e-01]\n",
      " [8.53362400e-03 9.91466403e-01]\n",
      " [2.27703974e-01 7.72296011e-01]\n",
      " [9.73823130e-01 2.61769034e-02]\n",
      " [9.85255003e-01 1.47449952e-02]\n",
      " [9.88904893e-01 1.10951038e-02]\n",
      " [9.88432705e-01 1.15672341e-02]\n",
      " [9.90965843e-01 9.03417170e-03]\n",
      " [9.88320708e-01 1.16793085e-02]\n",
      " [9.85612512e-01 1.43875349e-02]\n",
      " [9.81530368e-01 1.84696931e-02]\n",
      " [9.77427244e-01 2.25727540e-02]\n",
      " [9.76538599e-01 2.34614126e-02]\n",
      " [9.43412542e-01 5.65875210e-02]\n",
      " [9.78112102e-01 2.18879785e-02]\n",
      " [8.16429138e-01 1.83570877e-01]\n",
      " [9.30417717e-01 6.95822239e-02]\n",
      " [8.78927708e-01 1.21072300e-01]\n",
      " [9.94025588e-01 5.97441429e-03]\n",
      " [9.96001661e-01 3.99833126e-03]\n",
      " [9.98176575e-01 1.82340527e-03]\n",
      " [9.97123182e-01 2.87677464e-03]\n",
      " [9.97998655e-01 2.00129417e-03]\n",
      " [9.97209489e-01 2.79053114e-03]\n",
      " [9.92330551e-01 7.66941160e-03]\n",
      " [9.27279592e-01 7.27204010e-02]\n",
      " [9.43770528e-01 5.62294871e-02]\n",
      " [9.96519089e-01 3.48092709e-03]\n",
      " [9.88425374e-01 1.15746465e-02]\n",
      " [9.90752101e-01 9.24784970e-03]\n",
      " [9.94906425e-01 5.09356754e-03]\n",
      " [9.94603574e-01 5.39643224e-03]\n",
      " [9.92560625e-01 7.43945641e-03]\n",
      " [9.93668377e-01 6.33162353e-03]\n",
      " [8.47461224e-01 1.52538791e-01]\n",
      " [7.72177577e-01 2.27822393e-01]\n",
      " [4.79106992e-01 5.20893037e-01]\n",
      " [2.40227342e-01 7.59772718e-01]\n",
      " [9.89116848e-01 1.08831692e-02]\n",
      " [9.89717364e-01 1.02826217e-02]\n",
      " [9.93788064e-01 6.21190015e-03]\n",
      " [9.81592596e-01 1.84074119e-02]\n",
      " [9.93437588e-01 6.56242622e-03]\n",
      " [9.93135929e-01 6.86404016e-03]\n",
      " [4.15338948e-02 9.58466053e-01]\n",
      " [7.50743318e-03 9.92492616e-01]\n",
      " [7.09904917e-03 9.92900968e-01]\n",
      " [5.07378904e-03 9.94926214e-01]\n",
      " [5.57208853e-03 9.94427919e-01]\n",
      " [9.38928314e-03 9.90610659e-01]\n",
      " [6.56396570e-03 9.93436098e-01]\n",
      " [9.41635966e-01 5.83640933e-02]\n",
      " [9.47964728e-01 5.20352274e-02]\n",
      " [9.78846967e-01 2.11529657e-02]\n",
      " [9.66508329e-01 3.34916748e-02]\n",
      " [9.63521719e-01 3.64783145e-02]\n",
      " [9.95259583e-01 4.74046823e-03]\n",
      " [9.97494817e-01 2.50522862e-03]\n",
      " [9.96840239e-01 3.15972464e-03]\n",
      " [8.55971456e-01 1.44028604e-01]\n",
      " [9.86786187e-01 1.32138133e-02]\n",
      " [2.59484146e-02 9.74051535e-01]\n",
      " [2.20566578e-02 9.77943301e-01]\n",
      " [2.80571599e-02 9.71942782e-01]\n",
      " [4.20094356e-02 9.57990587e-01]\n",
      " [5.94477868e-03 9.94055152e-01]\n",
      " [3.21187153e-02 9.67881322e-01]\n",
      " [9.81993437e-01 1.80065930e-02]\n",
      " [9.93258834e-01 6.74117869e-03]\n",
      " [9.90277290e-01 9.72273946e-03]\n",
      " [9.94529426e-01 5.47057390e-03]\n",
      " [9.95757282e-01 4.24269633e-03]\n",
      " [9.96314824e-01 3.68524343e-03]\n",
      " [9.93236125e-01 6.76386291e-03]\n",
      " [9.96930063e-01 3.06994631e-03]\n",
      " [9.96708155e-01 3.29179573e-03]\n",
      " [9.95151520e-01 4.84850956e-03]\n",
      " [9.98201847e-01 1.79814908e-03]\n",
      " [9.95750427e-01 4.24961234e-03]\n",
      " [8.94375682e-01 1.05624333e-01]\n",
      " [9.66751933e-01 3.32481042e-02]\n",
      " [2.10806206e-01 7.89193809e-01]\n",
      " [8.82194281e-01 1.17805742e-01]\n",
      " [9.79376018e-01 2.06240080e-02]\n",
      " [9.36275065e-01 6.37249723e-02]\n",
      " [9.72658098e-01 2.73419358e-02]\n",
      " [7.88686752e-01 2.11313277e-01]\n",
      " [9.36608016e-01 6.33919686e-02]\n",
      " [9.76812422e-01 2.31876262e-02]\n",
      " [9.40107048e-01 5.98929711e-02]\n",
      " [9.94205773e-01 5.79420058e-03]\n",
      " [9.97023404e-01 2.97658308e-03]\n",
      " [9.98008430e-01 1.99163379e-03]\n",
      " [9.90835428e-01 9.16452706e-03]\n",
      " [9.96870100e-01 3.12991743e-03]\n",
      " [9.95349824e-01 4.65016486e-03]\n",
      " [9.95477736e-01 4.52232035e-03]\n",
      " [9.96065557e-01 3.93449003e-03]\n",
      " [9.95604277e-01 4.39575128e-03]\n",
      " [9.96871412e-01 3.12865339e-03]\n",
      " [9.96798456e-01 3.20161413e-03]\n",
      " [9.95372832e-01 4.62716725e-03]\n",
      " [9.93204713e-01 6.79523870e-03]\n",
      " [9.96565163e-01 3.43485386e-03]\n",
      " [9.97021377e-01 2.97855074e-03]\n",
      " [9.70489323e-01 2.95106508e-02]\n",
      " [9.33133543e-01 6.68664724e-02]\n",
      " [9.92763817e-01 7.23619526e-03]\n",
      " [9.97541547e-01 2.45844899e-03]\n",
      " [9.96492326e-01 3.50769609e-03]\n",
      " [9.91771281e-01 8.22866056e-03]\n",
      " [9.94452775e-01 5.54725435e-03]\n",
      " [9.97533441e-01 2.46656872e-03]\n",
      " [9.97200489e-01 2.79956893e-03]\n",
      " [9.96669114e-01 3.33085074e-03]\n",
      " [9.96144652e-01 3.85537278e-03]\n",
      " [9.96981442e-01 3.01853474e-03]\n",
      " [9.09742892e-01 9.02571380e-02]\n",
      " [8.83296072e-01 1.16703905e-01]\n",
      " [9.97032404e-01 2.96761235e-03]\n",
      " [9.98343110e-01 1.65691134e-03]\n",
      " [8.79990697e-01 1.20009303e-01]\n",
      " [8.57667863e-01 1.42332181e-01]\n",
      " [7.74503499e-03 9.92254972e-01]\n",
      " [1.34258434e-01 8.65741611e-01]\n",
      " [1.05405385e-02 9.89459515e-01]\n",
      " [9.91666853e-01 8.33315309e-03]\n",
      " [8.23919773e-01 1.76080272e-01]\n",
      " [6.68944359e-01 3.31055611e-01]\n",
      " [7.46205961e-03 9.92537916e-01]\n",
      " [3.94278485e-03 9.96057272e-01]\n",
      " [2.84056179e-02 9.71594393e-01]\n",
      " [8.95292640e-01 1.04707345e-01]\n",
      " [9.27573860e-01 7.24261105e-02]\n",
      " [9.29393589e-01 7.06064180e-02]\n",
      " [9.93051767e-01 6.94825128e-03]\n",
      " [9.91394579e-01 8.60537868e-03]\n",
      " [9.97555554e-01 2.44451431e-03]\n",
      " [9.98244762e-01 1.75525586e-03]\n",
      " [9.96700823e-01 3.29917460e-03]\n",
      " [9.94734526e-01 5.26547804e-03]\n",
      " [9.96953011e-01 3.04694683e-03]\n",
      " [9.21587586e-01 7.84124658e-02]\n",
      " [9.87738132e-01 1.22619281e-02]\n",
      " [9.91115332e-01 8.88467208e-03]\n",
      " [9.95815337e-01 4.18460928e-03]\n",
      " [9.97634411e-01 2.36559915e-03]\n",
      " [9.98136044e-01 1.86396251e-03]\n",
      " [9.94350731e-01 5.64927002e-03]\n",
      " [9.94653225e-01 5.34678716e-03]\n",
      " [9.95932400e-01 4.06758720e-03]\n",
      " [9.78471696e-01 2.15282738e-02]\n",
      " [9.76071596e-01 2.39283778e-02]\n",
      " [9.94786263e-01 5.21365134e-03]\n",
      " [9.98198688e-01 1.80134515e-03]\n",
      " [9.98502612e-01 1.49743608e-03]\n",
      " [9.98269916e-01 1.73004973e-03]\n",
      " [9.96886313e-01 3.11364164e-03]\n",
      " [9.95169699e-01 4.83024819e-03]\n",
      " [9.94903326e-01 5.09670284e-03]\n",
      " [9.98235822e-01 1.76421180e-03]\n",
      " [9.96738017e-01 3.26198246e-03]\n",
      " [9.98044491e-01 1.95546309e-03]\n",
      " [9.97613668e-01 2.38635531e-03]\n",
      " [9.97275054e-01 2.72496580e-03]\n",
      " [6.82193087e-03 9.93178010e-01]\n",
      " [1.12867072e-01 8.87132943e-01]\n",
      " [9.56844985e-01 4.31550220e-02]\n",
      " [9.55348372e-01 4.46516350e-02]\n",
      " [8.51943612e-01 1.48056358e-01]\n",
      " [6.42657816e-01 3.57342124e-01]\n",
      " [9.57982481e-01 4.20175232e-02]\n",
      " [1.93575367e-01 8.06424677e-01]\n",
      " [9.84864533e-01 1.51354754e-02]\n",
      " [9.55902696e-01 4.40972969e-02]\n",
      " [9.84078765e-01 1.59212146e-02]\n",
      " [9.91881192e-01 8.11881665e-03]\n",
      " [9.97458041e-01 2.54199957e-03]\n",
      " [9.98196661e-01 1.80333026e-03]\n",
      " [9.96414781e-01 3.58522381e-03]\n",
      " [6.12487316e-01 3.87512624e-01]\n",
      " [2.65227761e-02 9.73477244e-01]\n",
      " [8.25402141e-01 1.74597844e-01]\n",
      " [5.89133101e-03 9.94108677e-01]\n",
      " [7.33556552e-03 9.92664397e-01]\n",
      " [5.83135476e-03 9.94168639e-01]\n",
      " [4.10782779e-03 9.95892167e-01]\n",
      " [5.39815752e-03 9.94601846e-01]\n",
      " [7.53736496e-03 9.92462635e-01]\n",
      " [1.01473760e-02 9.89852607e-01]\n",
      " [8.07418395e-03 9.91925776e-01]\n",
      " [5.42632759e-01 4.57367241e-01]\n",
      " [1.27675496e-02 9.87232447e-01]\n",
      " [8.87634277e-01 1.12365723e-01]\n",
      " [4.74881474e-03 9.95251179e-01]\n",
      " [3.60831269e-03 9.96391714e-01]\n",
      " [1.29919231e-01 8.70080829e-01]\n",
      " [5.93504636e-03 9.94064987e-01]\n",
      " [6.21903967e-03 9.93780911e-01]\n",
      " [1.15625523e-02 9.88437474e-01]\n",
      " [1.05772121e-02 9.89422739e-01]\n",
      " [7.51485815e-03 9.92485106e-01]\n",
      " [5.95788471e-03 9.94042099e-01]\n",
      " [7.36049330e-03 9.92639542e-01]\n",
      " [1.69708468e-02 9.83029127e-01]\n",
      " [7.81017840e-02 9.21898246e-01]\n",
      " [9.40065324e-01 5.99346459e-02]\n",
      " [7.82878816e-01 2.17121214e-01]\n",
      " [9.84230220e-01 1.57697443e-02]\n",
      " [9.85219836e-01 1.47801787e-02]\n",
      " [9.89789307e-01 1.02106435e-02]\n",
      " [9.90334094e-01 9.66593809e-03]\n",
      " [9.82959747e-01 1.70402266e-02]\n",
      " [9.33084190e-01 6.69158101e-02]\n",
      " [9.87097502e-01 1.29024824e-02]\n",
      " [9.84851778e-01 1.51482178e-02]\n",
      " [9.90234613e-01 9.76536702e-03]\n",
      " [9.85148430e-01 1.48515673e-02]\n",
      " [9.80546534e-01 1.94534864e-02]\n",
      " [9.83797014e-01 1.62030011e-02]\n",
      " [9.77584064e-01 2.24159639e-02]\n",
      " [9.88966644e-01 1.10333497e-02]\n",
      " [9.81224179e-01 1.87758356e-02]\n",
      " [9.54234660e-01 4.57653180e-02]\n",
      " [5.94237864e-01 4.05762106e-01]\n",
      " [3.49030733e-01 6.50969267e-01]\n",
      " [9.97546852e-01 2.45316187e-03]\n",
      " [9.12217617e-01 8.77824053e-02]\n",
      " [9.89149749e-01 1.08502852e-02]\n",
      " [9.90982592e-01 9.01744422e-03]\n",
      " [9.96657252e-01 3.34271253e-03]\n",
      " [9.96010542e-01 3.98943294e-03]\n",
      " [9.90198374e-01 9.80169140e-03]\n",
      " [9.77152407e-01 2.28475612e-02]\n",
      " [9.89989042e-01 1.00109857e-02]\n",
      " [9.95681763e-01 4.31821262e-03]\n",
      " [9.94951010e-01 5.04898187e-03]\n",
      " [9.95802939e-01 4.19705501e-03]\n",
      " [9.96324301e-01 3.67573136e-03]\n",
      " [9.97103631e-01 2.89639411e-03]\n",
      " [9.85531092e-01 1.44689288e-02]\n",
      " [9.78838325e-01 2.11616457e-02]\n",
      " [9.91531372e-01 8.46866239e-03]\n",
      " [9.95753169e-01 4.24686493e-03]\n",
      " [9.96224642e-01 3.77536309e-03]\n",
      " [9.98031676e-01 1.96832069e-03]\n",
      " [9.97358024e-01 2.64198822e-03]\n",
      " [9.94090617e-01 5.90939960e-03]\n",
      " [9.57235515e-01 4.27645333e-02]\n",
      " [9.87895608e-01 1.21043986e-02]\n",
      " [9.88700986e-01 1.12989675e-02]\n",
      " [9.82946754e-01 1.70532092e-02]\n",
      " [9.77236092e-01 2.27639247e-02]\n",
      " [9.91753042e-01 8.24693963e-03]\n",
      " [9.60506320e-01 3.94936018e-02]\n",
      " [8.31007242e-01 1.68992758e-01]\n",
      " [7.24630296e-01 2.75369674e-01]\n",
      " [8.70247960e-01 1.29752055e-01]\n",
      " [9.96602297e-01 3.39765614e-03]\n",
      " [9.96943891e-01 3.05612059e-03]\n",
      " [9.94234741e-01 5.76524623e-03]\n",
      " [9.91762638e-01 8.23738705e-03]\n",
      " [9.91842031e-01 8.15792568e-03]\n",
      " [9.90489364e-01 9.51068569e-03]\n",
      " [9.95497465e-01 4.50251298e-03]\n",
      " [9.99265850e-01 7.34204776e-04]\n",
      " [9.98198688e-01 1.80128333e-03]\n",
      " [9.97370839e-01 2.62912945e-03]\n",
      " [9.98457909e-01 1.54212129e-03]\n",
      " [9.96691346e-01 3.30866501e-03]\n",
      " [9.96668637e-01 3.33135109e-03]\n",
      " [8.89383376e-01 1.10616639e-01]\n",
      " [9.78203654e-01 2.17963383e-02]\n",
      " [9.97016311e-01 2.98371818e-03]\n",
      " [9.28711116e-01 7.12888911e-02]\n",
      " [9.74767804e-01 2.52321865e-02]\n",
      " [9.92740452e-01 7.25954678e-03]\n",
      " [9.81879950e-01 1.81200691e-02]\n",
      " [9.95933473e-01 4.06655623e-03]\n",
      " [9.93598938e-01 6.40103873e-03]\n",
      " [9.94041026e-01 5.95900090e-03]\n",
      " [9.97491479e-01 2.50853132e-03]\n",
      " [9.96701539e-01 3.29844374e-03]\n",
      " [9.96712804e-01 3.28714796e-03]\n",
      " [9.93978024e-01 6.02191733e-03]\n",
      " [9.84867275e-01 1.51326749e-02]\n",
      " [9.97681975e-01 2.31797807e-03]\n",
      " [9.90132213e-01 9.86783672e-03]\n",
      " [8.73182297e-01 1.26817703e-01]\n",
      " [1.72306914e-02 9.82769310e-01]\n",
      " [5.02285128e-03 9.94977176e-01]\n",
      " [4.48317174e-03 9.95516837e-01]\n",
      " [5.77983819e-03 9.94220138e-01]\n",
      " [6.38742140e-03 9.93612587e-01]\n",
      " [2.43367583e-01 7.56632447e-01]\n",
      " [9.81565416e-01 1.84346158e-02]\n",
      " [9.90449727e-01 9.55031905e-03]\n",
      " [9.74106848e-01 2.58931592e-02]\n",
      " [9.90891397e-01 9.10865609e-03]\n",
      " [9.96522784e-01 3.47730005e-03]\n",
      " [9.94626820e-01 5.37322834e-03]\n",
      " [9.94921148e-01 5.07889502e-03]\n",
      " [9.95111763e-01 4.88829473e-03]\n",
      " [9.96805549e-01 3.19443922e-03]\n",
      " [9.97908235e-01 2.09179102e-03]\n",
      " [9.98104692e-01 1.89524330e-03]\n",
      " [9.97261167e-01 2.73886998e-03]\n",
      " [9.98143554e-01 1.85648107e-03]\n",
      " [9.96928990e-01 3.07107600e-03]\n",
      " [9.96942818e-01 3.05715506e-03]\n",
      " [9.97022450e-01 2.97759380e-03]\n",
      " [9.93621051e-01 6.37894077e-03]\n",
      " [9.79574203e-01 2.04258040e-02]\n",
      " [9.83389556e-01 1.66104045e-02]\n",
      " [9.86981094e-01 1.30188577e-02]\n",
      " [9.95707214e-01 4.29279078e-03]\n",
      " [9.96379673e-01 3.62039707e-03]\n",
      " [9.98046160e-01 1.95388286e-03]\n",
      " [9.96896863e-01 3.10316286e-03]\n",
      " [6.15347147e-01 3.84652823e-01]\n",
      " [2.57750414e-02 9.74224985e-01]\n",
      " [5.94995497e-03 9.94050026e-01]\n",
      " [5.54739544e-03 9.94452536e-01]\n",
      " [5.32398932e-03 9.94675994e-01]\n",
      " [6.01054868e-03 9.93989468e-01]\n",
      " [8.87268689e-03 9.91127312e-01]\n",
      " [9.49876197e-03 9.90501165e-01]\n",
      " [3.79168824e-03 9.96208310e-01]\n",
      " [8.65050498e-03 9.91349459e-01]\n",
      " [4.24291007e-03 9.95757043e-01]\n",
      " [4.74679377e-03 9.95253205e-01]\n",
      " [2.76223477e-02 9.72377717e-01]\n",
      " [1.93932001e-02 9.80606854e-01]\n",
      " [5.30230207e-03 9.94697690e-01]\n",
      " [4.68953364e-02 9.53104734e-01]\n",
      " [9.12393034e-01 8.76069292e-02]\n",
      " [9.82929587e-01 1.70703959e-02]\n",
      " [9.88120317e-01 1.18797012e-02]\n",
      " [9.90406215e-01 9.59377084e-03]\n",
      " [9.90059316e-01 9.94069688e-03]\n",
      " [9.90849376e-01 9.15068761e-03]\n",
      " [9.90979850e-01 9.02009383e-03]\n",
      " [9.71527755e-01 2.84721889e-02]\n",
      " [9.83347595e-01 1.66523997e-02]\n",
      " [9.90555584e-01 9.44444910e-03]\n",
      " [9.79074538e-01 2.09254287e-02]\n",
      " [9.76043046e-01 2.39569545e-02]\n",
      " [9.71766829e-01 2.82332096e-02]\n",
      " [9.68545437e-01 3.14544961e-02]\n",
      " [9.83305991e-01 1.66939814e-02]\n",
      " [9.62959945e-01 3.70400697e-02]\n",
      " [7.47045398e-01 2.52954543e-01]\n",
      " [9.95083094e-01 4.91692638e-03]\n",
      " [3.05345207e-02 9.69465435e-01]\n",
      " [5.03377197e-03 9.94966209e-01]\n",
      " [6.76199235e-03 9.93237972e-01]\n",
      " [3.55389132e-03 9.96446073e-01]\n",
      " [4.09142766e-03 9.95908618e-01]\n",
      " [8.62028450e-03 9.91379738e-01]\n",
      " [5.87370247e-03 9.94126320e-01]\n",
      " [4.95483167e-03 9.95045185e-01]\n",
      " [5.31523442e-03 9.94684756e-01]\n",
      " [6.03215024e-03 9.93967891e-01]\n",
      " [9.09635544e-01 9.03644189e-02]\n",
      " [9.13444579e-01 8.65554139e-02]\n",
      " [6.27669632e-01 3.72330308e-01]\n",
      " [7.52968490e-01 2.47031525e-01]\n",
      " [9.92741585e-01 7.25835375e-03]\n",
      " [9.89252508e-01 1.07475249e-02]\n",
      " [9.83412147e-01 1.65878870e-02]\n",
      " [9.92162764e-01 7.83728436e-03]\n",
      " [9.83009160e-01 1.69908423e-02]\n",
      " [9.60940301e-01 3.90596800e-02]\n",
      " [9.69245672e-01 3.07543352e-02]\n",
      " [9.67631221e-01 3.23687792e-02]\n",
      " [9.21459962e-03 9.90785360e-01]\n",
      " [7.11510563e-03 9.92884815e-01]\n",
      " [5.41041372e-03 9.94589567e-01]\n",
      " [4.70581371e-03 9.95294154e-01]\n",
      " [4.12657149e-02 9.58734334e-01]\n",
      " [9.72570717e-01 2.74292920e-02]\n",
      " [9.93819058e-01 6.18093647e-03]\n",
      " [9.82334733e-01 1.76652428e-02]\n",
      " [9.95736718e-01 4.26331069e-03]\n",
      " [9.96602178e-01 3.39785987e-03]\n",
      " [9.96943533e-01 3.05642257e-03]\n",
      " [9.97379959e-01 2.62007001e-03]\n",
      " [9.97457206e-01 2.54283752e-03]\n",
      " [9.97587442e-01 2.41258228e-03]\n",
      " [9.51774597e-01 4.82254401e-02]\n",
      " [9.97277439e-01 2.72262003e-03]\n",
      " [9.97861683e-01 2.13837414e-03]\n",
      " [9.91295695e-01 8.70423764e-03]\n",
      " [9.30450678e-01 6.95493892e-02]\n",
      " [9.34926689e-01 6.50732890e-02]\n",
      " [9.36747253e-01 6.32527322e-02]\n",
      " [9.78301883e-01 2.16980688e-02]\n",
      " [9.96230423e-01 3.76956956e-03]\n",
      " [9.97594774e-01 2.40521296e-03]\n",
      " [9.96782541e-01 3.21741193e-03]\n",
      " [9.93687809e-01 6.31222548e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5404bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_decision(test,pred):\n",
    "    h = np.array(pred)\n",
    "    action = []\n",
    "    status = \"N\"\n",
    "    for i in range(len(h)):\n",
    "        if h[i][0] == max(h[i]):\n",
    "            h[i] = [1,0]\n",
    "            if status == \"N\":\n",
    "                action.append(\"Buy\")\n",
    "                status = \"Buy\"\n",
    "            else:\n",
    "                action.append(\"Hold\")\n",
    "        else:\n",
    "            h[i] = [0,1]\n",
    "            if status == \"Buy\":\n",
    "                action.append(\"Sell\")\n",
    "                status = \"N\"\n",
    "            else:\n",
    "                action.append(\"Hold\")\n",
    "    return pd.DataFrame(action,index=test[10:].index,columns=[\"Action\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1a52ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20190116</th>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190117</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190118</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190122</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190123</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201224</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201228</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201229</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201230</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201231</th>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Action\n",
       "DATE           \n",
       "20190116    Buy\n",
       "20190117   Hold\n",
       "20190118   Hold\n",
       "20190122   Hold\n",
       "20190123   Hold\n",
       "...         ...\n",
       "20201224   Hold\n",
       "20201228   Hold\n",
       "20201229   Hold\n",
       "20201230   Hold\n",
       "20201231   Hold\n",
       "\n",
       "[495 rows x 1 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = convert_decision(test_X,predictions)\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c484a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtestdata = test_X[[\"open\"]][10:]\n",
    "backtestdata.columns = [\"Open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "93bd39a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20190116</th>\n",
       "      <td>37.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190117</th>\n",
       "      <td>37.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190118</th>\n",
       "      <td>38.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190122</th>\n",
       "      <td>38.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190123</th>\n",
       "      <td>37.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201224</th>\n",
       "      <td>130.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201228</th>\n",
       "      <td>133.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201229</th>\n",
       "      <td>137.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201230</th>\n",
       "      <td>134.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201231</th>\n",
       "      <td>133.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open\n",
       "DATE             \n",
       "20190116   37.209\n",
       "20190117   37.477\n",
       "20190118   38.280\n",
       "20190122   38.013\n",
       "20190123   37.464\n",
       "...           ...\n",
       "20201224  130.700\n",
       "20201228  133.360\n",
       "20201229  137.400\n",
       "20201230  134.910\n",
       "20201231  133.450\n",
       "\n",
       "[495 rows x 1 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtestdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ef890",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a3faf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Input ##########################\n",
    "# For hist_price_data: index=[\"date\"], columns = [\"Open\"]\n",
    "# For pred_action: index=[\"date\"], columns = [\"Action\"] (Buy/Sell)\n",
    "################### Output #########################\n",
    "# 1. trading record\n",
    "# 2. total profit\n",
    "class backtest:\n",
    "    hpd = \"\"\n",
    "    pred_action=\"\"\n",
    "    trade_record=pd.DataFrame(index=[],\n",
    "                              columns=[\"Action\",\"Price\",\"Position\",\"Cash\",\"Pos_Bal\",\"Cash_Bal\",\"Cum_Profit\"],\n",
    "                             )\n",
    "    capital = 0\n",
    "    cash_balance = 0\n",
    "    profit = 0\n",
    "    handle_fee = 0\n",
    "    position = 0\n",
    "    last_price = 0\n",
    "    \n",
    "    def __init__(self,hist_price_data,pred_action,capital,handling_fee):\n",
    "        self.hpd = hist_price_data\n",
    "        self.pred_action = pred_action\n",
    "        self.capital = capital\n",
    "        self.cash_balance = capital\n",
    "        self.handle_fee = handling_fee\n",
    "        \n",
    "    def start_test(self):        \n",
    "        # For loop to iterate the data\n",
    "        for ind in self.pred_action.index:\n",
    "            # Update latest price\n",
    "            self.last_price = self.hpd.loc[ind,\"Open\"]\n",
    "            \n",
    "            if self.pred_action.loc[ind,\"Action\"].lower() == \"buy\":\n",
    "                self.buy(ind,self.hpd.loc[ind,\"Open\"])\n",
    "            elif self.pred_action.loc[ind,\"Action\"].lower() == \"sell\":\n",
    "                self.sell(ind,self.hpd.loc[ind,\"Open\"])\n",
    "            else:\n",
    "                print(\"Did not buy at \" + str(ind))\n",
    "            \n",
    "                \n",
    "        \n",
    "    def mark_down_record(self,date,action,price,pos_delta,cash_delta):\n",
    "        self.trade_record.loc[date,\"Action\"] = action\n",
    "        self.trade_record.loc[date,\"Price\"] = price\n",
    "        self.trade_record.loc[date,\"Position\"] = pos_delta\n",
    "        self.trade_record.loc[date,\"Cash\"] = cash_delta\n",
    "        \n",
    "        self.trade_record.loc[date,\"Pos_Bal\"] = round(self.position,4)\n",
    "        self.trade_record.loc[date,\"Cash_Bal\"] = round(self.cash_balance,3)\n",
    "        self.trade_record.loc[date,\"Cum_Profit\"] = round(self.get_profit(),3)\n",
    "        \n",
    "    def buy(self,date,price):\n",
    "        # Assume use all money to buy all\n",
    "        buy_flag = False\n",
    "        buy_pos = floor(self.cash_balance / price)\n",
    "        for i in range(buy_pos):\n",
    "            act_buy_pos = buy_pos - i\n",
    "            total_amt = act_buy_pos*price*(1+self.handle_fee)\n",
    "            if self.cash_balance > total_amt:\n",
    "                self.position += act_buy_pos\n",
    "                self.cash_balance -= total_amt\n",
    "                self.mark_down_record(date,\n",
    "                                 \"Buy\",\n",
    "                                 price,\n",
    "                                 act_buy_pos,\n",
    "                                 -total_amt)\n",
    "                print(\"Bought at\",date,\"with price =\", price)\n",
    "                buy_flag = True\n",
    "                break\n",
    "        if not buy_flag:\n",
    "            print(\"You do not have enough money to buy!\")\n",
    "    \n",
    "    def sell(self,date,price):\n",
    "        # Assume sell all position\n",
    "        sell_pos = self.position\n",
    "        total_amt = sell_pos*price*(1-self.handle_fee)\n",
    "        if self.position >= 1:\n",
    "            self.position -= sell_pos\n",
    "            self.cash_balance += total_amt\n",
    "            self.mark_down_record(date,\n",
    "                             \"Sell\",\n",
    "                             price,\n",
    "                             -sell_pos,\n",
    "                             total_amt)\n",
    "            print(\"Sold at\",date,\"with price =\", price)\n",
    "        else:\n",
    "            print(\"You do not have enough position to sell!\")\n",
    "    \n",
    "    def get_profit(self):\n",
    "        return self.get_cash_balance()+self.get_last_price()*self.get_position()-self.get_capital()\n",
    "    \n",
    "    def get_capital(self):\n",
    "        return self.capital\n",
    "    \n",
    "    def get_last_price(self):\n",
    "        return self.last_price\n",
    "    \n",
    "    def get_cash_balance(self):\n",
    "        return self.cash_balance\n",
    "    \n",
    "    def get_position(self):\n",
    "        return self.position\n",
    "    \n",
    "    def get_amounnt(self):\n",
    "        return self.capital+self.profit\n",
    "    \n",
    "    def print_trade_record(self):\n",
    "        print(self.trade_record)\n",
    "        \n",
    "    def print_profit(self):\n",
    "        print(\"Overall Profit:\",self.get_profit())\n",
    "    \n",
    "    def export_trade_record(self,stock):\n",
    "        # Save the trade record to the path\n",
    "        self.trade_record.to_csv(\"trade_record/\"+stock+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d1c3ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = pd.DataFrame(data=[\"buy\",\"hold\",\"hold\",\"sell\",\"hold\",\"buy\"],\n",
    "                      index = [20201001,20201002,20201003,20201004,20201005,20201006],\n",
    "                      columns = [\"Action\"])\n",
    "hpd = pd.DataFrame(data=[124.05,126.4,127.5,126.5,129.9,130.2],\n",
    "                      index = [20201001,20201002,20201003,20201004,20201005,20201006],\n",
    "                      columns = [\"Open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "91f633b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_1 = backtest(backtestdata,final_pred,10000,0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d16ea2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bought at 20190116 with price = 37.209\n",
      "Did not buy at 20190117\n",
      "Did not buy at 20190118\n",
      "Did not buy at 20190122\n",
      "Did not buy at 20190123\n",
      "Did not buy at 20190124\n",
      "Did not buy at 20190125\n",
      "Did not buy at 20190128\n",
      "Did not buy at 20190129\n",
      "Did not buy at 20190130\n",
      "Did not buy at 20190131\n",
      "Did not buy at 20190201\n",
      "Did not buy at 20190204\n",
      "Did not buy at 20190205\n",
      "Did not buy at 20190206\n",
      "Did not buy at 20190207\n",
      "Did not buy at 20190208\n",
      "Did not buy at 20190211\n",
      "Did not buy at 20190212\n",
      "Did not buy at 20190213\n",
      "Did not buy at 20190214\n",
      "Did not buy at 20190215\n",
      "Did not buy at 20190219\n",
      "Did not buy at 20190220\n",
      "Did not buy at 20190221\n",
      "Did not buy at 20190222\n",
      "Did not buy at 20190225\n",
      "Did not buy at 20190226\n",
      "Did not buy at 20190227\n",
      "Did not buy at 20190228\n",
      "Did not buy at 20190301\n",
      "Did not buy at 20190304\n",
      "Did not buy at 20190305\n",
      "Did not buy at 20190306\n",
      "Did not buy at 20190307\n",
      "Did not buy at 20190308\n",
      "Sold at 20190311 with price = 42.837\n",
      "Bought at 20190312 with price = 43.937\n",
      "Did not buy at 20190313\n",
      "Did not buy at 20190314\n",
      "Did not buy at 20190315\n",
      "Did not buy at 20190318\n",
      "Did not buy at 20190319\n",
      "Did not buy at 20190320\n",
      "Did not buy at 20190321\n",
      "Did not buy at 20190322\n",
      "Did not buy at 20190325\n",
      "Did not buy at 20190326\n",
      "Did not buy at 20190327\n",
      "Did not buy at 20190328\n",
      "Did not buy at 20190329\n",
      "Did not buy at 20190401\n",
      "Did not buy at 20190402\n",
      "Did not buy at 20190403\n",
      "Did not buy at 20190404\n",
      "Did not buy at 20190405\n",
      "Did not buy at 20190408\n",
      "Did not buy at 20190409\n",
      "Did not buy at 20190410\n",
      "Did not buy at 20190411\n",
      "Did not buy at 20190412\n",
      "Did not buy at 20190415\n",
      "Did not buy at 20190416\n",
      "Did not buy at 20190417\n",
      "Did not buy at 20190418\n",
      "Did not buy at 20190422\n",
      "Did not buy at 20190423\n",
      "Did not buy at 20190424\n",
      "Did not buy at 20190425\n",
      "Did not buy at 20190426\n",
      "Did not buy at 20190429\n",
      "Did not buy at 20190430\n",
      "Sold at 20190501 with price = 51.23\n",
      "Bought at 20190502 with price = 51.222\n",
      "Did not buy at 20190503\n",
      "Did not buy at 20190506\n",
      "Did not buy at 20190507\n",
      "Did not buy at 20190508\n",
      "Did not buy at 20190509\n",
      "Sold at 20190510 with price = 48.374\n",
      "Did not buy at 20190513\n",
      "Did not buy at 20190514\n",
      "Did not buy at 20190515\n",
      "Did not buy at 20190516\n",
      "Did not buy at 20190517\n",
      "Did not buy at 20190520\n",
      "Did not buy at 20190521\n",
      "Did not buy at 20190522\n",
      "Did not buy at 20190523\n",
      "Did not buy at 20190524\n",
      "Did not buy at 20190528\n",
      "Did not buy at 20190529\n",
      "Did not buy at 20190530\n",
      "Did not buy at 20190531\n",
      "Did not buy at 20190603\n",
      "Did not buy at 20190604\n",
      "Did not buy at 20190605\n",
      "Bought at 20190606 with price = 44.86\n",
      "Did not buy at 20190607\n",
      "Did not buy at 20190610\n",
      "Did not buy at 20190611\n",
      "Did not buy at 20190612\n",
      "Did not buy at 20190613\n",
      "Did not buy at 20190614\n",
      "Did not buy at 20190617\n",
      "Did not buy at 20190618\n",
      "Did not buy at 20190619\n",
      "Did not buy at 20190620\n",
      "Did not buy at 20190621\n",
      "Did not buy at 20190624\n",
      "Did not buy at 20190625\n",
      "Did not buy at 20190626\n",
      "Did not buy at 20190627\n",
      "Did not buy at 20190628\n",
      "Did not buy at 20190701\n",
      "Did not buy at 20190702\n",
      "Did not buy at 20190703\n",
      "Did not buy at 20190705\n",
      "Did not buy at 20190708\n",
      "Did not buy at 20190709\n",
      "Did not buy at 20190710\n",
      "Did not buy at 20190711\n",
      "Did not buy at 20190712\n",
      "Did not buy at 20190715\n",
      "Did not buy at 20190716\n",
      "Did not buy at 20190717\n",
      "Did not buy at 20190718\n",
      "Did not buy at 20190719\n",
      "Did not buy at 20190722\n",
      "Did not buy at 20190723\n",
      "Sold at 20190724 with price = 50.883\n",
      "Did not buy at 20190725\n",
      "Bought at 20190726 with price = 50.839\n",
      "Did not buy at 20190729\n",
      "Did not buy at 20190730\n",
      "Did not buy at 20190731\n",
      "Did not buy at 20190801\n",
      "Did not buy at 20190802\n",
      "Sold at 20190805 with price = 48.512\n",
      "Did not buy at 20190806\n",
      "Did not buy at 20190807\n",
      "Did not buy at 20190808\n",
      "Did not buy at 20190809\n",
      "Did not buy at 20190812\n",
      "Did not buy at 20190813\n",
      "Bought at 20190814 with price = 49.968\n",
      "Did not buy at 20190815\n",
      "Did not buy at 20190816\n",
      "Did not buy at 20190819\n",
      "Did not buy at 20190820\n",
      "Did not buy at 20190821\n",
      "Did not buy at 20190822\n",
      "Did not buy at 20190823\n",
      "Did not buy at 20190826\n",
      "Did not buy at 20190827\n",
      "Sold at 20190828 with price = 50.203\n",
      "Did not buy at 20190829\n",
      "Did not buy at 20190830\n",
      "Did not buy at 20190903\n",
      "Did not buy at 20190904\n",
      "Did not buy at 20190905\n",
      "Bought at 20190906 with price = 52.649\n",
      "Did not buy at 20190909\n",
      "Did not buy at 20190910\n",
      "Did not buy at 20190911\n",
      "Did not buy at 20190912\n",
      "Did not buy at 20190913\n",
      "Did not buy at 20190916\n",
      "Did not buy at 20190917\n",
      "Did not buy at 20190918\n",
      "Did not buy at 20190919\n",
      "Did not buy at 20190920\n",
      "Did not buy at 20190923\n",
      "Did not buy at 20190924\n",
      "Did not buy at 20190925\n",
      "Sold at 20190926 with price = 54.112\n",
      "Bought at 20190927 with price = 54.247\n",
      "Did not buy at 20190930\n",
      "Did not buy at 20191001\n",
      "Did not buy at 20191002\n",
      "Did not buy at 20191003\n",
      "Did not buy at 20191004\n",
      "Did not buy at 20191007\n",
      "Did not buy at 20191008\n",
      "Did not buy at 20191009\n",
      "Did not buy at 20191010\n",
      "Did not buy at 20191011\n",
      "Did not buy at 20191014\n",
      "Did not buy at 20191015\n",
      "Did not buy at 20191016\n",
      "Did not buy at 20191017\n",
      "Did not buy at 20191018\n",
      "Did not buy at 20191021\n",
      "Did not buy at 20191022\n",
      "Did not buy at 20191023\n",
      "Did not buy at 20191024\n",
      "Did not buy at 20191025\n",
      "Did not buy at 20191028\n",
      "Did not buy at 20191029\n",
      "Did not buy at 20191030\n",
      "Did not buy at 20191031\n",
      "Did not buy at 20191101\n",
      "Did not buy at 20191104\n",
      "Did not buy at 20191105\n",
      "Did not buy at 20191106\n",
      "Did not buy at 20191107\n",
      "Did not buy at 20191108\n",
      "Did not buy at 20191111\n",
      "Did not buy at 20191112\n",
      "Did not buy at 20191113\n",
      "Did not buy at 20191114\n",
      "Did not buy at 20191115\n",
      "Did not buy at 20191118\n",
      "Did not buy at 20191119\n",
      "Did not buy at 20191120\n",
      "Did not buy at 20191121\n",
      "Did not buy at 20191122\n",
      "Sold at 20191125 with price = 64.812\n",
      "Did not buy at 20191126\n",
      "Did not buy at 20191127\n",
      "Bought at 20191129 with price = 65.768\n",
      "Did not buy at 20191202\n",
      "Did not buy at 20191203\n",
      "Sold at 20191204 with price = 64.405\n",
      "Did not buy at 20191205\n",
      "Did not buy at 20191206\n",
      "Bought at 20191209 with price = 66.61\n",
      "Did not buy at 20191210\n",
      "Did not buy at 20191211\n",
      "Did not buy at 20191212\n",
      "Did not buy at 20191213\n",
      "Did not buy at 20191216\n",
      "Did not buy at 20191217\n",
      "Did not buy at 20191218\n",
      "Did not buy at 20191219\n",
      "Did not buy at 20191220\n",
      "Did not buy at 20191223\n",
      "Did not buy at 20191224\n",
      "Did not buy at 20191226\n",
      "Did not buy at 20191227\n",
      "Did not buy at 20191230\n",
      "Did not buy at 20191231\n",
      "Did not buy at 20200102\n",
      "Did not buy at 20200103\n",
      "Did not buy at 20200106\n",
      "Did not buy at 20200107\n",
      "Did not buy at 20200108\n",
      "Did not buy at 20200109\n",
      "Did not buy at 20200110\n",
      "Did not buy at 20200113\n",
      "Did not buy at 20200114\n",
      "Did not buy at 20200115\n",
      "Did not buy at 20200116\n",
      "Did not buy at 20200117\n",
      "Did not buy at 20200121\n",
      "Did not buy at 20200122\n",
      "Did not buy at 20200123\n",
      "Did not buy at 20200124\n",
      "Did not buy at 20200127\n",
      "Sold at 20200128 with price = 77.118\n",
      "Did not buy at 20200129\n",
      "Bought at 20200130 with price = 79.081\n",
      "Did not buy at 20200131\n",
      "Did not buy at 20200203\n",
      "Did not buy at 20200204\n",
      "Did not buy at 20200205\n",
      "Sold at 20200206 with price = 79.579\n",
      "Bought at 20200207 with price = 79.717\n",
      "Did not buy at 20200210\n",
      "Did not buy at 20200211\n",
      "Did not buy at 20200212\n",
      "Did not buy at 20200213\n",
      "Did not buy at 20200214\n",
      "Did not buy at 20200218\n",
      "Did not buy at 20200219\n",
      "Sold at 20200220 with price = 79.781\n",
      "Bought at 20200221 with price = 78.791\n",
      "Sold at 20200224 with price = 73.51\n",
      "Did not buy at 20200225\n",
      "Did not buy at 20200226\n",
      "Did not buy at 20200227\n",
      "Did not buy at 20200228\n",
      "Did not buy at 20200302\n",
      "Did not buy at 20200303\n",
      "Did not buy at 20200304\n",
      "Bought at 20200305 with price = 73.078\n",
      "Sold at 20200306 with price = 69.733\n",
      "Bought at 20200309 with price = 65.222\n",
      "Sold at 20200310 with price = 68.53\n",
      "Did not buy at 20200311\n",
      "Did not buy at 20200312\n",
      "Did not buy at 20200313\n",
      "Did not buy at 20200316\n",
      "Did not buy at 20200317\n",
      "Did not buy at 20200318\n",
      "Did not buy at 20200319\n",
      "Did not buy at 20200320\n",
      "Did not buy at 20200323\n",
      "Did not buy at 20200324\n",
      "Did not buy at 20200325\n",
      "Bought at 20200326 with price = 60.96\n",
      "Did not buy at 20200327\n",
      "Did not buy at 20200330\n",
      "Did not buy at 20200331\n",
      "Did not buy at 20200401\n",
      "Did not buy at 20200402\n",
      "Did not buy at 20200403\n",
      "Did not buy at 20200406\n",
      "Did not buy at 20200407\n",
      "Did not buy at 20200408\n",
      "Did not buy at 20200409\n",
      "Did not buy at 20200413\n",
      "Did not buy at 20200414\n",
      "Did not buy at 20200415\n",
      "Did not buy at 20200416\n",
      "Did not buy at 20200417\n",
      "Did not buy at 20200420\n",
      "Did not buy at 20200421\n",
      "Did not buy at 20200422\n",
      "Sold at 20200423 with price = 68.22\n",
      "Bought at 20200424 with price = 68.546\n",
      "Did not buy at 20200427\n",
      "Did not buy at 20200428\n",
      "Did not buy at 20200429\n",
      "Did not buy at 20200430\n",
      "Did not buy at 20200501\n",
      "Did not buy at 20200504\n",
      "Did not buy at 20200505\n",
      "Did not buy at 20200506\n",
      "Did not buy at 20200507\n",
      "Did not buy at 20200508\n",
      "Did not buy at 20200511\n",
      "Did not buy at 20200512\n",
      "Did not buy at 20200513\n",
      "Did not buy at 20200514\n",
      "Did not buy at 20200515\n",
      "Did not buy at 20200518\n",
      "Did not buy at 20200519\n",
      "Did not buy at 20200520\n",
      "Did not buy at 20200521\n",
      "Did not buy at 20200522\n",
      "Did not buy at 20200526\n",
      "Did not buy at 20200527\n",
      "Did not buy at 20200528\n",
      "Did not buy at 20200529\n",
      "Did not buy at 20200601\n",
      "Did not buy at 20200602\n",
      "Did not buy at 20200603\n",
      "Did not buy at 20200604\n",
      "Did not buy at 20200605\n",
      "Did not buy at 20200608\n",
      "Did not buy at 20200609\n",
      "Did not buy at 20200610\n",
      "Did not buy at 20200611\n",
      "Did not buy at 20200612\n",
      "Did not buy at 20200615\n",
      "Did not buy at 20200616\n",
      "Did not buy at 20200617\n",
      "Did not buy at 20200618\n",
      "Did not buy at 20200619\n",
      "Did not buy at 20200622\n",
      "Did not buy at 20200623\n",
      "Did not buy at 20200624\n",
      "Did not buy at 20200625\n",
      "Did not buy at 20200626\n",
      "Did not buy at 20200629\n",
      "Did not buy at 20200630\n",
      "Did not buy at 20200701\n",
      "Did not buy at 20200702\n",
      "Did not buy at 20200706\n",
      "Did not buy at 20200707\n",
      "Did not buy at 20200708\n",
      "Did not buy at 20200709\n",
      "Did not buy at 20200710\n",
      "Did not buy at 20200713\n",
      "Did not buy at 20200714\n",
      "Did not buy at 20200715\n",
      "Did not buy at 20200716\n",
      "Did not buy at 20200717\n",
      "Did not buy at 20200720\n",
      "Did not buy at 20200721\n",
      "Did not buy at 20200722\n",
      "Did not buy at 20200723\n",
      "Sold at 20200724 with price = 90.242\n",
      "Did not buy at 20200727\n",
      "Did not buy at 20200728\n",
      "Did not buy at 20200729\n",
      "Did not buy at 20200730\n",
      "Did not buy at 20200731\n",
      "Bought at 20200803 with price = 107.31\n",
      "Did not buy at 20200804\n",
      "Did not buy at 20200805\n",
      "Did not buy at 20200806\n",
      "Did not buy at 20200807\n",
      "Did not buy at 20200810\n",
      "Did not buy at 20200811\n",
      "Did not buy at 20200812\n",
      "Did not buy at 20200813\n",
      "Did not buy at 20200814\n",
      "Did not buy at 20200817\n",
      "Did not buy at 20200818\n",
      "Did not buy at 20200819\n",
      "Did not buy at 20200820\n",
      "Did not buy at 20200821\n",
      "Did not buy at 20200824\n",
      "Did not buy at 20200825\n",
      "Did not buy at 20200826\n",
      "Did not buy at 20200827\n",
      "Did not buy at 20200828\n",
      "Did not buy at 20200831\n",
      "Did not buy at 20200901\n",
      "Did not buy at 20200902\n",
      "Did not buy at 20200903\n",
      "Did not buy at 20200904\n",
      "Sold at 20200908 with price = 113.22\n",
      "Did not buy at 20200909\n",
      "Did not buy at 20200910\n",
      "Did not buy at 20200911\n",
      "Did not buy at 20200914\n",
      "Did not buy at 20200915\n",
      "Did not buy at 20200916\n",
      "Did not buy at 20200917\n",
      "Did not buy at 20200918\n",
      "Did not buy at 20200921\n",
      "Did not buy at 20200922\n",
      "Did not buy at 20200923\n",
      "Did not buy at 20200924\n",
      "Did not buy at 20200925\n",
      "Did not buy at 20200928\n",
      "Bought at 20200929 with price = 113.82\n",
      "Did not buy at 20200930\n",
      "Did not buy at 20201001\n",
      "Did not buy at 20201002\n",
      "Did not buy at 20201005\n",
      "Did not buy at 20201006\n",
      "Did not buy at 20201007\n",
      "Did not buy at 20201008\n",
      "Did not buy at 20201009\n",
      "Did not buy at 20201012\n",
      "Did not buy at 20201013\n",
      "Did not buy at 20201014\n",
      "Did not buy at 20201015\n",
      "Did not buy at 20201016\n",
      "Did not buy at 20201019\n",
      "Did not buy at 20201020\n",
      "Did not buy at 20201021\n",
      "Did not buy at 20201022\n",
      "Sold at 20201023 with price = 115.65\n",
      "Did not buy at 20201026\n",
      "Did not buy at 20201027\n",
      "Did not buy at 20201028\n",
      "Did not buy at 20201029\n",
      "Did not buy at 20201030\n",
      "Did not buy at 20201102\n",
      "Did not buy at 20201103\n",
      "Did not buy at 20201104\n",
      "Did not buy at 20201105\n",
      "Bought at 20201106 with price = 117.76\n",
      "Did not buy at 20201109\n",
      "Did not buy at 20201110\n",
      "Did not buy at 20201111\n",
      "Did not buy at 20201112\n",
      "Did not buy at 20201113\n",
      "Did not buy at 20201116\n",
      "Did not buy at 20201117\n",
      "Did not buy at 20201118\n",
      "Did not buy at 20201119\n",
      "Did not buy at 20201120\n",
      "Did not buy at 20201123\n",
      "Sold at 20201124 with price = 113.38\n",
      "Did not buy at 20201125\n",
      "Did not buy at 20201127\n",
      "Did not buy at 20201130\n",
      "Did not buy at 20201201\n",
      "Bought at 20201202 with price = 121.45\n",
      "Did not buy at 20201203\n",
      "Did not buy at 20201204\n",
      "Did not buy at 20201207\n",
      "Did not buy at 20201208\n",
      "Did not buy at 20201209\n",
      "Did not buy at 20201210\n",
      "Did not buy at 20201211\n",
      "Did not buy at 20201214\n",
      "Did not buy at 20201215\n",
      "Did not buy at 20201216\n",
      "Did not buy at 20201217\n",
      "Did not buy at 20201218\n",
      "Did not buy at 20201221\n",
      "Did not buy at 20201222\n",
      "Did not buy at 20201223\n",
      "Did not buy at 20201224\n",
      "Did not buy at 20201228\n",
      "Did not buy at 20201229\n",
      "Did not buy at 20201230\n",
      "Did not buy at 20201231\n"
     ]
    }
   ],
   "source": [
    "backtest_1.start_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8518f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Action   Price Position          Cash Pos_Bal   Cash_Bal Cum_Profit\n",
      "20190116    Buy  37.209      268  -9991.956024     268      8.044    -19.944\n",
      "20190311   Sell  42.837     -268  11457.355368       0  11465.399   1465.399\n",
      "20190312    Buy  43.937      260  -11446.46724     260     18.932   1442.552\n",
      "20190501   Sell   51.23     -260    13293.1604       0  13312.093   3312.093\n",
      "20190502    Buy  51.222      259 -13293.030996     259     19.062    3285.56\n",
      "20190510   Sell  48.374     -259  12503.808268       0   12522.87    2522.87\n",
      "20190606    Buy   44.86      278  -12496.02216     278     26.848   2497.928\n",
      "20190724   Sell  50.883     -278  14117.183052       0  14144.031   4144.031\n",
      "20190726    Buy  50.839      277 -14110.567806     277     33.463   4115.866\n",
      "20190805   Sell  48.512     -277  13410.948352       0  13444.411   3444.411\n",
      "20190814    Buy  49.968      268 -13418.206848     268     26.204   3417.628\n",
      "20190828   Sell  50.203     -268  13427.495192       0    13453.7     3453.7\n",
      "20190906    Buy  52.649      255  -13452.34599     255      1.354   3426.849\n",
      "20190926   Sell  54.112     -255   13770.96288       0  13772.316   3772.316\n",
      "20190927    Buy  54.247      253 -13751.939982     253     20.376   3744.867\n",
      "20191125   Sell  64.812     -253  16364.641128       0  16385.018   6385.018\n",
      "20191129    Buy  65.768      248 -16343.084928     248     41.933   6352.397\n",
      "20191204   Sell  64.405     -248   15940.49512       0  15982.428   5982.428\n",
      "20191209    Buy   66.61      239  -15951.62958     239     30.798   5950.588\n",
      "20200128   Sell  77.118     -239  18394.339596       0  18425.138   8425.138\n",
      "20200130    Buy  79.081      232 -18383.485584     232     41.652   8388.444\n",
      "20200206   Sell  79.579     -232  18425.403344       0  18467.056   8467.056\n",
      "20200207    Buy  79.717      231 -18451.456254     231     15.599   8430.226\n",
      "20200220   Sell  79.781     -231  18392.552178       0  18408.151   8408.151\n",
      "20200221    Buy  78.791      233 -18395.019606     233     13.132   8371.435\n",
      "20200224   Sell   73.51     -233   17093.57434       0  17106.706   7106.706\n",
      "20200305    Buy  73.078      233 -17061.228348     233     45.478   7072.652\n",
      "20200306   Sell  69.733     -233  16215.293422       0  16260.771   6260.771\n",
      "20200309    Buy  65.222      248 -16207.406112     248     53.365   6228.421\n",
      "20200310   Sell   68.53     -248   16961.44912       0  17014.814   7014.814\n",
      "20200326    Buy   60.96      278  -16980.77376     278     34.041   6980.921\n",
      "20200423   Sell   68.22     -278   18927.22968       0   18961.27    8961.27\n",
      "20200424    Buy  68.546      276 -18956.533392     276      4.737   8923.433\n",
      "20200724   Sell  90.242     -276  24856.978416       0  24861.715  14861.715\n",
      "20200803    Buy  107.31      231  -24838.18722     231     23.528  14812.138\n",
      "20200908   Sell  113.22     -231   26101.51236       0   26125.04   16125.04\n",
      "20200929    Buy  113.82      229  -26116.90956     229      8.131  16072.911\n",
      "20201023   Sell  115.65     -229    26430.8823       0  26439.013  16439.013\n",
      "20201106    Buy  117.76      224  -26430.99648     224      8.017  16386.257\n",
      "20201124   Sell  113.38     -224   25346.32576       0  25354.342  15354.342\n",
      "20201202    Buy  121.45      208   -25312.1232     208     42.219  15303.819\n",
      "==========================\n",
      "17799.81920599999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "backtest_1.print_trade_record()\n",
    "print('==========================')\n",
    "backtest_1.export_trade_record(\"AAPL\")\n",
    "backtest_1.print_profit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e585fcb",
   "metadata": {},
   "source": [
    "# Support Vectore Rgression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6ed53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
