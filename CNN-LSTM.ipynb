{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33e652d",
   "metadata": {},
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad005eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from stockstats import StockDataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03bed7",
   "metadata": {},
   "source": [
    "### Set the data source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2436b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data source path\n",
    "interval = \"daily\"\n",
    "region = \"us\"\n",
    "ex_product = \"nasdaq stocks\"\n",
    "section = \"1\"\n",
    "stock = \"aapl\"\n",
    "data_path = \"test_data/\"+interval+\"/\"+region+\"/\"+ex_product+\"/\"+section+\"/\"+stock+\".\"+region+\".txt\"\n",
    "\n",
    "# Use Apple .Inc stock for training\n",
    "\n",
    "# Extract only the OLHC\n",
    "column_to_use = [\"OPEN\",\"LOW\",\"HIGH\",\"CLOSE\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f91fe",
   "metadata": {},
   "source": [
    "### Load the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92c24ac-3419-4a42-973b-e21ae036c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ori_data = pd.read_csv(data_path, sep=\",\")\n",
    "\n",
    "# Rename the column names\n",
    "ori_data.columns = [colname[1:-1] for colname in ori_data.columns]\n",
    "\n",
    "# Drop the unnecessary\n",
    "ori_data.index = ori_data[\"DATE\"]\n",
    "ori_data = ori_data.drop(columns=['DATE','PER','TIME', 'TICKER', 'OPENINT'])\n",
    "ori_data.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be882ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19840907</th>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.10274</td>\n",
       "      <td>0.10028</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>96970899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840910</th>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.09905</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>75265237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840911</th>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.10456</td>\n",
       "      <td>0.10181</td>\n",
       "      <td>0.10274</td>\n",
       "      <td>177479896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840912</th>\n",
       "      <td>0.10274</td>\n",
       "      <td>0.10334</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>155043826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840913</th>\n",
       "      <td>0.10518</td>\n",
       "      <td>0.10548</td>\n",
       "      <td>0.10518</td>\n",
       "      <td>0.10518</td>\n",
       "      <td>241475025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211021</th>\n",
       "      <td>148.81000</td>\n",
       "      <td>149.64000</td>\n",
       "      <td>147.87000</td>\n",
       "      <td>149.48000</td>\n",
       "      <td>61420990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211022</th>\n",
       "      <td>149.69000</td>\n",
       "      <td>150.18000</td>\n",
       "      <td>148.64000</td>\n",
       "      <td>148.69000</td>\n",
       "      <td>58883443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211025</th>\n",
       "      <td>148.68000</td>\n",
       "      <td>149.37000</td>\n",
       "      <td>147.62110</td>\n",
       "      <td>148.64000</td>\n",
       "      <td>50720556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211026</th>\n",
       "      <td>149.33000</td>\n",
       "      <td>150.84000</td>\n",
       "      <td>149.01010</td>\n",
       "      <td>149.32000</td>\n",
       "      <td>60893395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211027</th>\n",
       "      <td>149.36000</td>\n",
       "      <td>149.73000</td>\n",
       "      <td>148.49000</td>\n",
       "      <td>148.85000</td>\n",
       "      <td>55925403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9362 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open       high        low      close     volume\n",
       "DATE                                                           \n",
       "19840907    0.10150    0.10274    0.10028    0.10150   96970899\n",
       "19840910    0.10150    0.10181    0.09905    0.10090   75265237\n",
       "19840911    0.10181    0.10456    0.10181    0.10274  177479896\n",
       "19840912    0.10274    0.10334    0.09966    0.09966  155043826\n",
       "19840913    0.10518    0.10548    0.10518    0.10518  241475025\n",
       "...             ...        ...        ...        ...        ...\n",
       "20211021  148.81000  149.64000  147.87000  149.48000   61420990\n",
       "20211022  149.69000  150.18000  148.64000  148.69000   58883443\n",
       "20211025  148.68000  149.37000  147.62110  148.64000   50720556\n",
       "20211026  149.33000  150.84000  149.01010  149.32000   60893395\n",
       "20211027  149.36000  149.73000  148.49000  148.85000   55925403\n",
       "\n",
       "[9362 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966120a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use online package to generate additional features\n",
    "x = StockDataFrame(ori_data)\n",
    "data = x[['open','high','low','close','volume',\n",
    "          'boll', 'boll_ub', 'boll_lb',\n",
    "          'macd', 'macdh', 'macds',\n",
    "          'rsi_11', 'rsi_14', 'rsi_21']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f7671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79d78dbc",
   "metadata": {},
   "source": [
    "### Split the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0daf1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_split(data,start,end):\n",
    "    train = (data.index >= start) & (data.index <= end)\n",
    "    train_X = data[train]\n",
    "    \n",
    "    return train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cd6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = custom_split(data,start = 20130101,end = 20171031)\n",
    "valid_X = custom_split(data,start = 20171101,end = 20181231)\n",
    "test_X = custom_split(data,start = 20190101,end = 20201231)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce609a",
   "metadata": {},
   "source": [
    "### Label the target result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e4e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we use 10 days price data to predict opening price of the 11th day\n",
    "num_day_to_predict = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f127afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_result_target_price(X,num_day,result_col_name = \"result_price\"):\n",
    "    y = pd.DataFrame(np.nan, index=X.index, columns=[result_col_name])\n",
    "    for i in range(len(X)-num_day):\n",
    "        y.iloc[i+num_day_to_predict,0] = X.iloc[i+num_day,0]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fcaaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = produce_result_target_price(train_X,num_day_to_predict)\n",
    "valid_y = produce_result_target_price(valid_X,num_day_to_predict)\n",
    "test_y = produce_result_target_price(test_X,num_day_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db1064e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20171101</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171102</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171103</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171106</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171107</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181224</th>\n",
       "      <td>36.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181226</th>\n",
       "      <td>36.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181227</th>\n",
       "      <td>37.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181228</th>\n",
       "      <td>38.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181231</th>\n",
       "      <td>38.526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          result_price\n",
       "DATE                  \n",
       "20171101           NaN\n",
       "20171102           NaN\n",
       "20171103           NaN\n",
       "20171106           NaN\n",
       "20171107           NaN\n",
       "...                ...\n",
       "20181224        36.007\n",
       "20181226        36.044\n",
       "20181227        37.876\n",
       "20181228        38.280\n",
       "20181231        38.526\n",
       "\n",
       "[292 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a8ca1",
   "metadata": {},
   "source": [
    "### Transform the X, y data into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b8773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_to_tensor(X,y,num_day):\n",
    "    # Initiate tensor for X\n",
    "    x_first = X.iloc[0:num_day,:]\n",
    "    x_mean = x_first.mean(axis=0) # Get the mean of the 10-day frame\n",
    "    x_std = x_first.std(axis=0) # Get the std of the 10-day frame\n",
    "    x_first = x_first.sub(x_mean, axis=1).div(x_std, axis=1) # Normalize the 10-day frame here\n",
    "    \n",
    "    # Initiate tensor for y\n",
    "    x_open = X.iloc[0:num_day,0]\n",
    "    y_val = y.iloc[num_day,:] # Get the corresponding y\n",
    "    y_val = y_val.sub(x_open.mean(axis=0)).div(x_open.std(axis=0)) # Normalize the y\n",
    "    \n",
    "    x_tf_data = [tf.convert_to_tensor(np.array(x_first),dtype = tf.float32)]\n",
    "    y_tf_data = [tf.convert_to_tensor(np.array(y_val),dtype = tf.float32)]\n",
    "    \n",
    "    for i in range(1,len(X)-num_day):   \n",
    "        x_window = X.iloc[i:i+num_day,:] # Set the window as a 10-day frame \n",
    "        x_mean = x_window.mean(axis=0) # Get the mean of the 10-day frame\n",
    "        x_std = x_window.std(axis=0) # Get the std of the 10-day frame\n",
    "        x_window = x_window.sub(x_mean, axis=1).div(x_std, axis=1) # Normalize the 10-day frame here\n",
    "        \n",
    "        x_open = X.iloc[i:i+num_day,0] # Get the opening price of the 10-day frame\n",
    "        y_val = y.iloc[i+num_day,:] # Get the corresponding y\n",
    "        y_val = y_val.sub(x_open.mean(axis=0)).div(x_open.std(axis=0)) # Normalize the y\n",
    "        \n",
    "        x_next_tf = tf.convert_to_tensor(np.array(x_window),dtype = tf.float32)\n",
    "        x_tf_data = tf.concat([x_tf_data, [x_next_tf]], 0)\n",
    "        \n",
    "        y_next_tf = tf.convert_to_tensor(np.array(y_val),dtype = tf.float32)\n",
    "        y_tf_data = tf.concat([y_tf_data, [y_next_tf]], 0)\n",
    "    return (tf.reshape(x_tf_data,(-1,10,14,1)),y_tf_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b66168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 19:43:12.523098: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-09 19:43:12.523598: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "tf_train_X,tf_train_y = transform_data_to_tensor(train_X,train_y,num_day_to_predict)\n",
    "tf_valid_X,tf_valid_y = transform_data_to_tensor(valid_X,valid_y,num_day_to_predict)\n",
    "tf_test_X,tf_test_y = transform_data_to_tensor(test_X,test_y,num_day_to_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f49a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1208, 10, 14, 1)\n",
      "(1208, 1)\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "(282, 10, 14, 1)\n",
      "(282, 1)\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "(495, 10, 14, 1)\n",
      "(495, 1)\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(tf_train_X.shape)\n",
    "print(tf_train_y.shape)\n",
    "print(tf_train_X.dtype)\n",
    "print(tf_train_y.dtype)\n",
    "\n",
    "print(tf_valid_X.shape)\n",
    "print(tf_valid_y.shape)\n",
    "print(tf_valid_X.dtype)\n",
    "print(tf_valid_y.dtype)\n",
    "\n",
    "print(tf_test_X.shape)\n",
    "print(tf_test_y.shape)\n",
    "print(tf_test_X.dtype)\n",
    "print(tf_test_y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e64c36",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "359468c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def myModel(input_shape,\n",
    "            encoder_unit = 100,\n",
    "            repeat_vector_n = 10):\n",
    "    \n",
    "    inputs = layers.Input(input_shape)\n",
    "    \n",
    "    print(\"Input: \",inputs.shape)\n",
    "    \n",
    "    # First Convolution + MaxPooling + Dropout\n",
    "    x = layers.Conv2D(filters = 64,kernel_size=(3,3), strides = (1,1), activation='relu', padding='valid')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2),strides=(2,1), padding='valid')(x)\n",
    "    x = layers.Dropout(rate = 0.01)(x)\n",
    "    print(\"1 Cov: \",x.shape)\n",
    "    \n",
    "    # Second Convolution + MaxPooling + Dropout\n",
    "    x = layers.Conv2D(filters = 16,kernel_size=(3,3), strides = (1,1), activation='relu', padding='valid')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2),strides=(2,1), padding='valid')(x)\n",
    "    x = layers.Dropout(rate = 0.01)(x)\n",
    "    print(\"2 Cov: \",x.shape)\n",
    "    \n",
    "    # Flatten Layer\n",
    "    x = layers.Flatten()(x)\n",
    "    print(\"Flatten: \",x.shape)\n",
    "    \n",
    "    # Repeat Vector Layer\n",
    "    x = layers.RepeatVector(n = repeat_vector_n)(x)\n",
    "    print(\"RepeatVector: \",x.shape)\n",
    "    \n",
    "    # Connect to LSTM\n",
    "    x = layers.LSTM(units = encoder_unit, input_shape=(5,1))(x)\n",
    "    print(\"LSTM: \",x.shape)\n",
    "    \n",
    "    # Add the Dense Layer with relu activation\n",
    "    x = layers.Dense(units = int(encoder_unit/2),activation = \"relu\")(x)\n",
    "    print(\"1 Dense: \",x.shape)\n",
    "    \n",
    "    # Add the last Dense Layer with sigmoid activation\n",
    "    outputs = layers.Dense(units = 1,activation = \"sigmoid\")(x)\n",
    "    print(\"Output: \",outputs.shape)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fc4f2",
   "metadata": {},
   "source": [
    "### Model Training and Fitting and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72215124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  (None, 10, 14, 1)\n",
      "1 Cov:  (None, 4, 11, 64)\n",
      "2 Cov:  (None, 1, 8, 16)\n",
      "Flatten:  (None, 128)\n",
      "RepeatVector:  (None, 50, 128)\n",
      "LSTM:  (None, 100)\n",
      "1 Dense:  (None, 50)\n",
      "Output:  (None, 1)\n",
      "Train on 1208 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 19:43:30.398207: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_18955_19440' and '__inference___backward_standard_lstm_18955_19440_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_19627' both implement 'lstm_7dca6800-06c8-486b-bfeb-b710db9c3913' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1299/1208 [================================] - 12s 10ms/sample - loss: 1.1750 - accuracy: 0.0000e+00 - mean_absolute_error: 1.1511\n",
      "Epoch 2/30\n",
      "1299/1208 [================================] - 10s 8ms/sample - loss: 1.0914 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0860\n",
      "Epoch 3/30\n",
      "1299/1208 [================================] - 10s 8ms/sample - loss: 1.1090 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0793\n",
      "Epoch 4/30\n",
      "1299/1208 [================================] - 10s 8ms/sample - loss: 1.1193 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0781\n",
      "Epoch 5/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0592 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0656\n",
      "Epoch 6/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0494 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0299\n",
      "Epoch 7/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0234 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0383\n",
      "Epoch 8/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0504 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0395\n",
      "Epoch 9/30\n",
      "1299/1208 [================================] - 10s 8ms/sample - loss: 1.0629 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0390\n",
      "Epoch 10/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0477 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0369\n",
      "Epoch 11/30\n",
      "1299/1208 [================================] - 10s 8ms/sample - loss: 1.0168 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0190\n",
      "Epoch 12/30\n",
      "1299/1208 [================================] - 10s 8ms/sample - loss: 1.0343 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0305\n",
      "Epoch 13/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0345 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0285\n",
      "Epoch 14/30\n",
      "1298/1208 [================================] - 11s 8ms/sample - loss: 1.0559 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0371\n",
      "Epoch 15/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0503 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0456\n",
      "Epoch 16/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0052 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0101\n",
      "Epoch 17/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0721 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0250\n",
      "Epoch 18/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0189 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0108\n",
      "Epoch 19/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0000 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0088\n",
      "Epoch 20/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0424 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0349\n",
      "Epoch 21/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0603 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0439\n",
      "Epoch 22/30\n",
      "1299/1208 [================================] - 10s 8ms/sample - loss: 0.9289 - accuracy: 0.0000e+00 - mean_absolute_error: 0.9417\n",
      "Epoch 23/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0258 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0306\n",
      "Epoch 24/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 0.9883 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0105\n",
      "Epoch 25/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0336 - accuracy: 0.0000e+00 - mean_absolute_error: 0.9996\n",
      "Epoch 26/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0466 - accuracy: 0.0000e+00 - mean_absolute_error: 0.9889\n",
      "Epoch 27/30\n",
      "1298/1208 [================================] - 11s 8ms/sample - loss: 1.0191 - accuracy: 0.0000e+00 - mean_absolute_error: 0.9922\n",
      "Epoch 28/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0010 - accuracy: 0.0000e+00 - mean_absolute_error: 0.9979\n",
      "Epoch 29/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 1.0089 - accuracy: 0.0000e+00 - mean_absolute_error: 0.9782\n",
      "Epoch 30/30\n",
      "1299/1208 [================================] - 11s 8ms/sample - loss: 0.9788 - accuracy: 0.0000e+00 - mean_absolute_error: 0.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 19:48:49.223654: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_32014_specialized_for_model_lstm_StatefulPartitionedCall_at___inference_distributed_function_32379' and '__inference_standard_lstm_32014' both implement 'lstm_c22aa3fd-2533-4344-869a-3890225ce6f3' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "282/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 4ms/sample - loss: 1.1139 - accuracy: 0.0000e+00 - mean_absolute_error: 1.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0466524802201183, 0.0, 1.0466526]\n",
      "===== Summary =====\n",
      "Epoch:  30\n",
      "Batch Size:  100\n",
      "Optimizer:  Adam\n",
      "Learning Rate:  0.005\n",
      "Encoder Units:  100\n",
      "Loss Function:  MAE\n",
      "Metrics:  MAE\n",
      "Validation:  [1.0466524802201183, 0.0, 1.0466526]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zh/ycxy1lsx5sx0g_2n4l8hfvph0000gn/T/ipykernel_38910/2200984352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Metrics: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_valid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                                 \u001b[0mbest_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                 \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "loss_list = [\"MAE\"]\n",
    "metric_list = [\"MAE\"]\n",
    "optimizer_list = [\"Adam\"]\n",
    "epoch_list = [30,50]\n",
    "batch_list = [100]\n",
    "encoder_list = [100]\n",
    "lr_list = [0.005]\n",
    "train_df = pd.DataFrame(columns = [\"Epoch\",\"Batch\",\"Optimizer\",\"LR\",\"Encoder Unit\",\"Loss\",\"Metrics\",\"Validation\"])\n",
    "best_model = \"\"\n",
    "best_valid = 99999\n",
    "metrics = [tf.keras.metrics.Accuracy()]\n",
    "\n",
    "for los in loss_list:\n",
    "    for met in metric_list:\n",
    "        for opti in optimizer_list:\n",
    "            for epochs in epoch_list:\n",
    "                for batchs in batch_list:\n",
    "                    for lr in lr_list:\n",
    "                        for encoder_u in encoder_list:\n",
    "\n",
    "                            model = myModel(input_shape=(num_day_to_predict,train_X.shape[1],1),\n",
    "                                            encoder_unit = encoder_u,\n",
    "                                            repeat_vector_n = 50\n",
    "                                           )\n",
    "\n",
    "                            if opti == \"Adam\":\n",
    "                                optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "                                \n",
    "                            if los == \"MAE\":\n",
    "                                loss = keras.losses.MeanAbsoluteError()\n",
    "                            elif los == \"MSE\":\n",
    "                                loss = keras.losses.MeanSquaredError()\n",
    "                                \n",
    "                            if met == \"MAE\":\n",
    "                                metrics.append(keras.metrics.MeanAbsoluteError())\n",
    "                            elif met == \"MSE\":\n",
    "                                metrics.append(keras.metrics.MeanSquaredError())\n",
    "                                \n",
    "                            model.compile(\n",
    "                                optimizer=optimizer,\n",
    "                                loss=loss,\n",
    "                                metrics=metrics,\n",
    "                            )\n",
    "\n",
    "                            history = model.fit(\n",
    "                                    tf_train_X,\n",
    "                                    tf_train_y,\n",
    "                                    epochs = epochs,\n",
    "                                    steps_per_epoch = batchs,\n",
    "                                )\n",
    "\n",
    "                            results = model.evaluate(tf_valid_X, tf_valid_y, batch_size=batchs)\n",
    "                            print(results)\n",
    "                            print(\"===== Summary =====\")\n",
    "                            print(\"Epoch: \",epochs)\n",
    "                            print(\"Batch Size: \",batchs)\n",
    "                            print(\"Optimizer: \",opti)\n",
    "                            print(\"Learning Rate: \",lr)\n",
    "                            print(\"Encoder Units: \",encoder_u)\n",
    "                            print(\"Loss Function: \", los)\n",
    "                            print(\"Metrics: \", met)\n",
    "                            print(\"Validation: \",results)\n",
    "                            if results < best_valid:\n",
    "                                best_valid = results\n",
    "                                best_model = model\n",
    "                            train_df = train_df.append({\"Epoch\": epochs,\n",
    "                                                        \"Batch\": batchs,\n",
    "                                                        \"Optimizer\": opti,\n",
    "                                                        \"LR\": lr,\n",
    "                                                        \"Encoder Unit\": encoder_u,\n",
    "                                                        \"Loss\": los,\n",
    "                                                        \"Metrics\": met,\n",
    "                                                        \"Validation\":results}, ignore_index=True)\n",
    "best_model.save(\"model/cnn_lstm_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1049860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_values(by=[\"Validation\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6201ca",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c93eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 19:54:25.620411: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_32763' and '__inference_standard_lstm_32652_specialized_for_model_lstm_StatefulPartitionedCall_at___inference_distributed_function_32962' both implement 'lstm_1fd2bea7-b47a-4e50-8364-97206a7cabc7' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (495, 1)\n",
      "[[9.96850729e-01]\n",
      " [9.99966264e-01]\n",
      " [9.99988079e-01]\n",
      " [9.99998629e-01]\n",
      " [9.99381721e-01]\n",
      " [3.37434918e-01]\n",
      " [1.94761038e-01]\n",
      " [3.90087605e-01]\n",
      " [6.92700088e-01]\n",
      " [9.99821782e-01]\n",
      " [9.99999642e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99994099e-01]\n",
      " [9.99997675e-01]\n",
      " [9.99997199e-01]\n",
      " [9.99991596e-01]\n",
      " [9.00944948e-01]\n",
      " [2.66435653e-01]\n",
      " [4.79991138e-01]\n",
      " [5.13820231e-01]\n",
      " [5.30334055e-01]\n",
      " [2.09321260e-01]\n",
      " [2.26758868e-01]\n",
      " [1.70374095e-01]\n",
      " [9.99958873e-01]\n",
      " [9.99999046e-01]\n",
      " [9.99996781e-01]\n",
      " [9.99999762e-01]\n",
      " [9.99998093e-01]\n",
      " [9.99999404e-01]\n",
      " [9.99983251e-01]\n",
      " [9.36651051e-01]\n",
      " [9.99983668e-01]\n",
      " [9.95517254e-01]\n",
      " [7.37708807e-02]\n",
      " [3.57925892e-05]\n",
      " [1.10268593e-06]\n",
      " [9.74969506e-01]\n",
      " [9.94908333e-01]\n",
      " [9.99997735e-01]\n",
      " [9.99991596e-01]\n",
      " [9.99999523e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99998569e-01]\n",
      " [9.99996781e-01]\n",
      " [9.99999523e-01]\n",
      " [9.99999404e-01]\n",
      " [4.20003682e-01]\n",
      " [1.59379303e-01]\n",
      " [1.68055296e-04]\n",
      " [3.03685665e-05]\n",
      " [4.37172353e-02]\n",
      " [1.33652478e-01]\n",
      " [9.17213440e-01]\n",
      " [9.99976158e-01]\n",
      " [9.99998510e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99999285e-01]\n",
      " [9.99922931e-01]\n",
      " [9.15700197e-01]\n",
      " [7.48686016e-01]\n",
      " [1.04022175e-01]\n",
      " [8.50822389e-01]\n",
      " [9.99995828e-01]\n",
      " [9.99995232e-01]\n",
      " [9.99996305e-01]\n",
      " [9.99999642e-01]\n",
      " [9.99999046e-01]\n",
      " [8.39503646e-01]\n",
      " [2.86653638e-03]\n",
      " [8.50647688e-04]\n",
      " [3.91057134e-03]\n",
      " [9.99968588e-01]\n",
      " [9.99937892e-01]\n",
      " [9.99954164e-01]\n",
      " [9.95941281e-01]\n",
      " [6.91029429e-03]\n",
      " [3.62992287e-05]\n",
      " [6.25848770e-06]\n",
      " [6.31809235e-06]\n",
      " [7.27862120e-04]\n",
      " [7.82102346e-04]\n",
      " [9.78946686e-04]\n",
      " [3.23057175e-05]\n",
      " [2.12550163e-04]\n",
      " [2.59876251e-05]\n",
      " [2.43782997e-05]\n",
      " [2.05338001e-05]\n",
      " [2.48551369e-05]\n",
      " [2.24709511e-05]\n",
      " [2.25603580e-05]\n",
      " [2.24411488e-05]\n",
      " [2.79843807e-05]\n",
      " [4.02629375e-05]\n",
      " [2.23517418e-05]\n",
      " [6.28868341e-02]\n",
      " [9.99229550e-01]\n",
      " [9.99986172e-01]\n",
      " [9.99995947e-01]\n",
      " [9.99995708e-01]\n",
      " [9.99993920e-01]\n",
      " [9.99929428e-01]\n",
      " [9.99980628e-01]\n",
      " [9.99950171e-01]\n",
      " [9.81139719e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99998808e-01]\n",
      " [9.99997854e-01]\n",
      " [9.99999225e-01]\n",
      " [9.99998927e-01]\n",
      " [6.81150496e-01]\n",
      " [9.99983728e-01]\n",
      " [9.87263799e-01]\n",
      " [3.32231462e-01]\n",
      " [9.99999523e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99989033e-01]\n",
      " [1.72799826e-03]\n",
      " [1.63793564e-04]\n",
      " [5.03039360e-03]\n",
      " [1.10268593e-06]\n",
      " [1.75665915e-02]\n",
      " [9.99996364e-01]\n",
      " [1.85523540e-01]\n",
      " [1.44613415e-01]\n",
      " [9.99993742e-01]\n",
      " [9.99702930e-01]\n",
      " [9.99989748e-01]\n",
      " [9.99995232e-01]\n",
      " [9.99958217e-01]\n",
      " [9.95780647e-01]\n",
      " [9.99995232e-01]\n",
      " [9.99919116e-01]\n",
      " [9.99998808e-01]\n",
      " [9.99999404e-01]\n",
      " [9.99999046e-01]\n",
      " [6.95845485e-03]\n",
      " [1.64890289e-03]\n",
      " [9.77516174e-06]\n",
      " [1.10268593e-06]\n",
      " [1.72555447e-04]\n",
      " [4.23192978e-04]\n",
      " [4.90248203e-05]\n",
      " [5.66461205e-01]\n",
      " [9.00023818e-01]\n",
      " [4.99479860e-01]\n",
      " [9.71071124e-01]\n",
      " [3.92152667e-01]\n",
      " [3.98912877e-01]\n",
      " [9.99996305e-01]\n",
      " [9.99993324e-01]\n",
      " [3.84216756e-01]\n",
      " [1.90557390e-01]\n",
      " [1.26220852e-01]\n",
      " [1.98394060e-04]\n",
      " [4.55260277e-04]\n",
      " [4.29153442e-05]\n",
      " [1.98692083e-04]\n",
      " [2.32747644e-01]\n",
      " [9.99618113e-01]\n",
      " [9.99984026e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99997973e-01]\n",
      " [9.99999046e-01]\n",
      " [9.99998808e-01]\n",
      " [9.95156288e-01]\n",
      " [7.52393782e-01]\n",
      " [6.12933517e-01]\n",
      " [4.42466408e-01]\n",
      " [9.82320428e-01]\n",
      " [1.56542659e-03]\n",
      " [2.64251232e-03]\n",
      " [3.40518355e-03]\n",
      " [3.29110622e-02]\n",
      " [4.18356061e-03]\n",
      " [1.82113051e-03]\n",
      " [9.99984682e-01]\n",
      " [9.99965191e-01]\n",
      " [2.61940867e-01]\n",
      " [6.06054068e-03]\n",
      " [9.98814583e-01]\n",
      " [3.93517762e-01]\n",
      " [9.78912354e-01]\n",
      " [6.90966785e-01]\n",
      " [9.99955237e-01]\n",
      " [9.99986053e-01]\n",
      " [9.99998331e-01]\n",
      " [9.99578118e-01]\n",
      " [9.99627709e-01]\n",
      " [9.99932528e-01]\n",
      " [9.99996424e-01]\n",
      " [9.99998569e-01]\n",
      " [9.99998510e-01]\n",
      " [9.99998689e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99997854e-01]\n",
      " [9.99999523e-01]\n",
      " [9.54963446e-01]\n",
      " [6.40294552e-02]\n",
      " [7.04270959e-01]\n",
      " [9.98648703e-01]\n",
      " [9.99998510e-01]\n",
      " [9.99913335e-01]\n",
      " [9.99992013e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99997556e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99998569e-01]\n",
      " [9.99998629e-01]\n",
      " [9.99464869e-01]\n",
      " [9.99973655e-01]\n",
      " [9.99998450e-01]\n",
      " [8.61900330e-01]\n",
      " [9.97111499e-02]\n",
      " [8.61346722e-04]\n",
      " [3.58223915e-05]\n",
      " [2.08809972e-03]\n",
      " [1.34196818e-01]\n",
      " [9.96517897e-01]\n",
      " [6.96690500e-01]\n",
      " [1.61355495e-01]\n",
      " [2.31266022e-05]\n",
      " [2.24709511e-05]\n",
      " [3.15308571e-05]\n",
      " [7.67633021e-02]\n",
      " [9.99986410e-01]\n",
      " [9.97102022e-01]\n",
      " [9.99988437e-01]\n",
      " [9.99995470e-01]\n",
      " [9.99998927e-01]\n",
      " [9.99998808e-01]\n",
      " [9.99998689e-01]\n",
      " [9.99997795e-01]\n",
      " [9.99992132e-01]\n",
      " [9.99999225e-01]\n",
      " [9.99999225e-01]\n",
      " [9.99816418e-01]\n",
      " [9.99997497e-01]\n",
      " [9.99998271e-01]\n",
      " [9.99997854e-01]\n",
      " [9.99996305e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99998450e-01]\n",
      " [9.52561617e-01]\n",
      " [9.95807111e-01]\n",
      " [9.99997616e-01]\n",
      " [9.99998927e-01]\n",
      " [9.99998748e-01]\n",
      " [9.99961972e-01]\n",
      " [9.99998808e-01]\n",
      " [6.85525060e-01]\n",
      " [7.80351698e-01]\n",
      " [9.10833180e-01]\n",
      " [9.99725819e-01]\n",
      " [7.60338128e-01]\n",
      " [9.99993265e-01]\n",
      " [9.99996424e-01]\n",
      " [4.76270914e-04]\n",
      " [5.84372878e-03]\n",
      " [5.19237578e-01]\n",
      " [8.52465987e-01]\n",
      " [7.36325979e-03]\n",
      " [9.40397382e-03]\n",
      " [1.10268593e-06]\n",
      " [1.25497580e-04]\n",
      " [2.36907840e-01]\n",
      " [5.61282039e-03]\n",
      " [7.00068474e-02]\n",
      " [3.29285860e-04]\n",
      " [9.98691738e-01]\n",
      " [9.99998450e-01]\n",
      " [4.38931465e-01]\n",
      " [5.77867031e-04]\n",
      " [6.02355599e-03]\n",
      " [2.66522169e-04]\n",
      " [7.26372004e-04]\n",
      " [3.57329845e-05]\n",
      " [1.98304653e-04]\n",
      " [3.45110893e-05]\n",
      " [3.34978104e-05]\n",
      " [2.39014626e-05]\n",
      " [2.09271908e-04]\n",
      " [1.11660361e-03]\n",
      " [1.90258026e-04]\n",
      " [2.36176401e-01]\n",
      " [2.00927258e-04]\n",
      " [2.22325325e-05]\n",
      " [2.12788582e-05]\n",
      " [2.80737877e-05]\n",
      " [2.24411488e-05]\n",
      " [3.04877758e-05]\n",
      " [3.43620777e-05]\n",
      " [3.45706940e-05]\n",
      " [1.69783831e-04]\n",
      " [3.38852406e-05]\n",
      " [2.24709511e-05]\n",
      " [2.21133232e-05]\n",
      " [2.55107880e-05]\n",
      " [1.18029118e-03]\n",
      " [9.00801182e-01]\n",
      " [6.13716960e-01]\n",
      " [9.98334348e-01]\n",
      " [3.29157233e-01]\n",
      " [1.24014378e-01]\n",
      " [7.06315041e-05]\n",
      " [9.69395041e-03]\n",
      " [2.42814541e-01]\n",
      " [9.99966383e-01]\n",
      " [9.99978483e-01]\n",
      " [9.99767780e-01]\n",
      " [6.77965105e-01]\n",
      " [9.99951661e-01]\n",
      " [9.99998748e-01]\n",
      " [9.99997139e-01]\n",
      " [9.99998808e-01]\n",
      " [3.64489883e-01]\n",
      " [8.63013268e-02]\n",
      " [1.21326149e-02]\n",
      " [9.47117805e-05]\n",
      " [6.43157959e-03]\n",
      " [2.86015660e-01]\n",
      " [7.12382793e-03]\n",
      " [9.99991655e-01]\n",
      " [9.99997258e-01]\n",
      " [9.99998808e-01]\n",
      " [9.85731006e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99999404e-01]\n",
      " [9.99996662e-01]\n",
      " [9.99997914e-01]\n",
      " [9.99998033e-01]\n",
      " [9.99998450e-01]\n",
      " [5.31542897e-01]\n",
      " [9.78955328e-02]\n",
      " [1.19142324e-01]\n",
      " [9.92524505e-01]\n",
      " [9.99884009e-01]\n",
      " [9.99999166e-01]\n",
      " [9.99998689e-01]\n",
      " [9.99992251e-01]\n",
      " [9.99981642e-01]\n",
      " [9.97572303e-01]\n",
      " [9.99898374e-01]\n",
      " [9.99351621e-01]\n",
      " [9.99553323e-01]\n",
      " [9.99978542e-01]\n",
      " [9.99995232e-01]\n",
      " [9.99850154e-01]\n",
      " [9.99999404e-01]\n",
      " [9.99996901e-01]\n",
      " [9.99998927e-01]\n",
      " [9.99998808e-01]\n",
      " [9.99980569e-01]\n",
      " [9.89813924e-01]\n",
      " [9.99989450e-01]\n",
      " [9.99730587e-01]\n",
      " [9.99999523e-01]\n",
      " [9.97386813e-01]\n",
      " [9.99962926e-01]\n",
      " [9.99997854e-01]\n",
      " [9.99998927e-01]\n",
      " [9.99999404e-01]\n",
      " [8.22836757e-01]\n",
      " [8.52395535e-01]\n",
      " [9.17971134e-04]\n",
      " [1.01557702e-01]\n",
      " [8.82998824e-01]\n",
      " [9.79374528e-01]\n",
      " [9.99998331e-01]\n",
      " [9.99943852e-01]\n",
      " [9.99997973e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99816298e-01]\n",
      " [9.99999404e-01]\n",
      " [9.99999523e-01]\n",
      " [9.99998450e-01]\n",
      " [9.91339803e-01]\n",
      " [2.17625499e-03]\n",
      " [9.51171994e-01]\n",
      " [5.20990193e-02]\n",
      " [3.97303402e-02]\n",
      " [5.76078892e-05]\n",
      " [2.51829624e-05]\n",
      " [5.28991222e-05]\n",
      " [6.31809235e-06]\n",
      " [2.24709511e-05]\n",
      " [2.84001827e-02]\n",
      " [9.99998331e-01]\n",
      " [9.99998748e-01]\n",
      " [9.99945164e-01]\n",
      " [9.99953568e-01]\n",
      " [9.99996126e-01]\n",
      " [9.99995112e-01]\n",
      " [9.99993205e-01]\n",
      " [6.81774616e-01]\n",
      " [8.76493931e-01]\n",
      " [9.99996066e-01]\n",
      " [9.99998569e-01]\n",
      " [4.86571878e-01]\n",
      " [9.99932349e-01]\n",
      " [9.99953091e-01]\n",
      " [9.99997973e-01]\n",
      " [9.99999464e-01]\n",
      " [9.99999285e-01]\n",
      " [9.99745965e-01]\n",
      " [9.99954700e-01]\n",
      " [9.99977469e-01]\n",
      " [6.83831811e-01]\n",
      " [9.99998808e-01]\n",
      " [9.99997616e-01]\n",
      " [9.99998450e-01]\n",
      " [4.27633524e-04]\n",
      " [3.57925892e-05]\n",
      " [3.56137753e-05]\n",
      " [3.56733799e-05]\n",
      " [4.89830971e-04]\n",
      " [1.33454800e-04]\n",
      " [2.17258930e-05]\n",
      " [2.18153000e-05]\n",
      " [1.95801258e-05]\n",
      " [2.38418579e-05]\n",
      " [2.31564045e-05]\n",
      " [2.25305557e-05]\n",
      " [2.83694267e-03]\n",
      " [1.84759796e-02]\n",
      " [4.64320183e-05]\n",
      " [5.76142967e-02]\n",
      " [2.31519341e-03]\n",
      " [5.38898349e-01]\n",
      " [9.99989748e-01]\n",
      " [9.99975622e-01]\n",
      " [9.97919083e-01]\n",
      " [6.03711605e-01]\n",
      " [9.99937773e-01]\n",
      " [2.77897984e-01]\n",
      " [9.96368229e-01]\n",
      " [6.41992509e-01]\n",
      " [9.99998569e-01]\n",
      " [9.99999583e-01]\n",
      " [9.99971569e-01]\n",
      " [9.99541700e-01]\n",
      " [3.83938700e-01]\n",
      " [1.87176764e-02]\n",
      " [1.03324652e-04]\n",
      " [9.89139080e-05]\n",
      " [2.33650208e-05]\n",
      " [2.17854977e-05]\n",
      " [2.11894512e-05]\n",
      " [2.22623348e-05]\n",
      " [4.80711460e-04]\n",
      " [1.25096023e-01]\n",
      " [1.36876106e-03]\n",
      " [2.24709511e-05]\n",
      " [1.04308128e-04]\n",
      " [2.24411488e-05]\n",
      " [2.44246423e-02]\n",
      " [9.99639571e-01]\n",
      " [9.99915481e-01]\n",
      " [9.99330521e-01]\n",
      " [9.99956369e-01]\n",
      " [9.99733925e-01]\n",
      " [2.20917672e-01]\n",
      " [9.98746216e-01]\n",
      " [5.96641600e-01]\n",
      " [1.31984085e-01]\n",
      " [9.50694084e-05]\n",
      " [4.62919474e-04]\n",
      " [5.81443310e-05]\n",
      " [9.34600830e-04]\n",
      " [4.25700843e-02]\n",
      " [1.35617852e-02]\n",
      " [9.99979258e-01]\n",
      " [9.99998450e-01]\n",
      " [9.99983549e-01]\n",
      " [9.99994159e-01]\n",
      " [9.99873877e-01]\n",
      " [9.99961853e-01]\n",
      " [9.99989510e-01]\n",
      " [7.93885350e-01]\n",
      " [1.05586320e-01]\n",
      " [9.20775235e-02]\n",
      " [2.32160091e-05]\n",
      " [9.99998450e-01]\n",
      " [9.99998569e-01]\n",
      " [9.99997973e-01]\n",
      " [9.99996781e-01]\n",
      " [9.99998093e-01]\n",
      " [9.99999046e-01]\n",
      " [9.99999583e-01]\n",
      " [9.98706043e-01]\n",
      " [9.99997854e-01]\n",
      " [9.99997973e-01]\n",
      " [6.57697856e-01]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('model/cnn_lstm_best')\n",
    "\n",
    "predictions = loaded_model.predict(tf_test_X)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5404bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanAndStd(X,y,num_day):\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    for i in range(0,len(X)-num_day): \n",
    "        x_open = X.iloc[i:i+num_day,0]\n",
    "        mean_list.append(x_open.mean(axis=0))\n",
    "        std_list.append(x_open.std(axis=0))\n",
    "    mean_df = pd.DataFrame(mean_list, columns = [\"mean\"])\n",
    "    std_df = pd.DataFrame(std_list, columns = [\"std\"])\n",
    "    return (mean_df,std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ca8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean, test_std = getMeanAndStd(test_X, test_y, num_day_to_predict)\n",
    "final_pred = predictions*np.array(test_std) + np.array(test_mean)\n",
    "final_test_y = test_y.iloc[num_day_to_predict: , :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b54cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1659f5e",
   "metadata": {},
   "source": [
    "### Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d53847",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_date = 20190101\n",
    "plot_end_date = 20201231\n",
    "keep = (final_test_y.index >= plot_start_date) & (final_test_y.index <= plot_end_date)\n",
    "final_pred = pd.DataFrame(data=final_pred,index = final_test_y.index, columns = [\"Predicted\"])\n",
    "plot_test_y = final_test_y[keep]\n",
    "plot_pred = final_pred[keep]\n",
    "\n",
    "string_index =  plot_test_y.index.map(str)\n",
    "\n",
    "plt.plot(string_index, plot_test_y[\"result_price\"], label = \"Actual\", color = 'Black')\n",
    "plt.plot(string_index, plot_pred[\"Predicted\"], label = \"Predicted\", color = 'Orange')\n",
    "plt.xlabel(\"timestamp\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.title(\"Prediction of \"+stock.upper()+\" using CNN-LSTM\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"plot/CNN_LSTM/\"+stock.upper()+\"-day(\"+str(num_day_to_predict)+\").jpg\",\n",
    "            dpi=600)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617290e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = pd.concat([plot_test_y,plot_pred], ignore_index=True, sort=False,axis=1)\n",
    "abc.columns = [\"Actual\",\"Predicted\"]\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cf67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3faf527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
